{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_arr = [c for c in \n",
    "    'SEPabcdefghijklmnopqrstuvwxyz단어나무놀이소녀키스사랑']\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "dic_len = len(num_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_data = [['word', '단어'], ['wood', '나무'],\n",
    "            ['game', '놀이'], ['girl', '소녀'],\n",
    "            ['kiss', '키스'], ['love', '사랑']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch(seq_data):\n",
    "    input_batch, output_batch, target_batch = [], [], []\n",
    "\n",
    "    for seq in seq_data:\n",
    "        input = [num_dic[n] for n in seq[0]]\n",
    "        output = [num_dic[n] for n in ('S' + seq[1])]\n",
    "        target = [num_dic[n] for n in (seq[1] + 'E')]\n",
    "\n",
    "        input_batch.append(np.eye(dic_len)[input])\n",
    "        output_batch.append(np.eye(dic_len)[output])\n",
    "        target_batch.append(target)\n",
    "\n",
    "    return input_batch, output_batch, target_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "n_hidden = 128\n",
    "total_epoch = 100\n",
    "n_class = n_input = dic_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_input = tf.placeholder(tf.float32, \n",
    "                           [None, None, n_input])\n",
    "dec_input = tf.placeholder(tf.float32, \n",
    "                           [None, None, n_input])\n",
    "targets = tf.placeholder(tf.int64, [None, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('encode'):\n",
    "    enc_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    enc_cell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "        enc_cell, output_keep_prob=0.5)\n",
    "\n",
    "    outputs, enc_states = tf.nn.dynamic_rnn(\n",
    "        enc_cell, enc_input, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope('decode'):\n",
    "    dec_cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "    dec_cell = tf.nn.rnn_cell.DropoutWrapper(\n",
    "        dec_cell, output_keep_prob=0.5)\n",
    "\n",
    "    outputs, dec_states = tf.nn.dynamic_rnn(\n",
    "        dec_cell, dec_input, initial_state=enc_states, \n",
    "        dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.layers.dense(outputs, n_class, activation=None)\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "    tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=model, labels=targets))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(\n",
    "    learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 3.710475\n",
      "Epoch: 0002 cost = 2.620276\n",
      "Epoch: 0003 cost = 1.543407\n",
      "Epoch: 0004 cost = 1.249719\n",
      "Epoch: 0005 cost = 0.707627\n",
      "Epoch: 0006 cost = 0.529583\n",
      "Epoch: 0007 cost = 0.572436\n",
      "Epoch: 0008 cost = 0.254951\n",
      "Epoch: 0009 cost = 0.185563\n",
      "Epoch: 0010 cost = 0.194928\n",
      "Epoch: 0011 cost = 0.075562\n",
      "Epoch: 0012 cost = 0.133786\n",
      "Epoch: 0013 cost = 0.042282\n",
      "Epoch: 0014 cost = 0.059581\n",
      "Epoch: 0015 cost = 0.031583\n",
      "Epoch: 0016 cost = 0.028749\n",
      "Epoch: 0017 cost = 0.017789\n",
      "Epoch: 0018 cost = 0.011733\n",
      "Epoch: 0019 cost = 0.074032\n",
      "Epoch: 0020 cost = 0.029123\n",
      "Epoch: 0021 cost = 0.034889\n",
      "Epoch: 0022 cost = 0.049170\n",
      "Epoch: 0023 cost = 0.013903\n",
      "Epoch: 0024 cost = 0.057146\n",
      "Epoch: 0025 cost = 0.005182\n",
      "Epoch: 0026 cost = 0.054996\n",
      "Epoch: 0027 cost = 0.008042\n",
      "Epoch: 0028 cost = 0.024208\n",
      "Epoch: 0029 cost = 0.010874\n",
      "Epoch: 0030 cost = 0.006040\n",
      "Epoch: 0031 cost = 0.041981\n",
      "Epoch: 0032 cost = 0.011818\n",
      "Epoch: 0033 cost = 0.007656\n",
      "Epoch: 0034 cost = 0.005764\n",
      "Epoch: 0035 cost = 0.002764\n",
      "Epoch: 0036 cost = 0.003729\n",
      "Epoch: 0037 cost = 0.007513\n",
      "Epoch: 0038 cost = 0.035262\n",
      "Epoch: 0039 cost = 0.005122\n",
      "Epoch: 0040 cost = 0.001192\n",
      "Epoch: 0041 cost = 0.006467\n",
      "Epoch: 0042 cost = 0.004508\n",
      "Epoch: 0043 cost = 0.004368\n",
      "Epoch: 0044 cost = 0.002243\n",
      "Epoch: 0045 cost = 0.002657\n",
      "Epoch: 0046 cost = 0.003429\n",
      "Epoch: 0047 cost = 0.001444\n",
      "Epoch: 0048 cost = 0.001880\n",
      "Epoch: 0049 cost = 0.004558\n",
      "Epoch: 0050 cost = 0.005150\n",
      "Epoch: 0051 cost = 0.003022\n",
      "Epoch: 0052 cost = 0.000760\n",
      "Epoch: 0053 cost = 0.001665\n",
      "Epoch: 0054 cost = 0.015606\n",
      "Epoch: 0055 cost = 0.002216\n",
      "Epoch: 0056 cost = 0.000728\n",
      "Epoch: 0057 cost = 0.001051\n",
      "Epoch: 0058 cost = 0.001052\n",
      "Epoch: 0059 cost = 0.002413\n",
      "Epoch: 0060 cost = 0.001004\n",
      "Epoch: 0061 cost = 0.001923\n",
      "Epoch: 0062 cost = 0.000808\n",
      "Epoch: 0063 cost = 0.004354\n",
      "Epoch: 0064 cost = 0.000543\n",
      "Epoch: 0065 cost = 0.002268\n",
      "Epoch: 0066 cost = 0.000589\n",
      "Epoch: 0067 cost = 0.001532\n",
      "Epoch: 0068 cost = 0.000480\n",
      "Epoch: 0069 cost = 0.003390\n",
      "Epoch: 0070 cost = 0.000868\n",
      "Epoch: 0071 cost = 0.000989\n",
      "Epoch: 0072 cost = 0.000799\n",
      "Epoch: 0073 cost = 0.000626\n",
      "Epoch: 0074 cost = 0.000700\n",
      "Epoch: 0075 cost = 0.001477\n",
      "Epoch: 0076 cost = 0.000728\n",
      "Epoch: 0077 cost = 0.000590\n",
      "Epoch: 0078 cost = 0.000217\n",
      "Epoch: 0079 cost = 0.000744\n",
      "Epoch: 0080 cost = 0.000561\n",
      "Epoch: 0081 cost = 0.001068\n",
      "Epoch: 0082 cost = 0.002340\n",
      "Epoch: 0083 cost = 0.001430\n",
      "Epoch: 0084 cost = 0.000455\n",
      "Epoch: 0085 cost = 0.000313\n",
      "Epoch: 0086 cost = 0.011750\n",
      "Epoch: 0087 cost = 0.000359\n",
      "Epoch: 0088 cost = 0.001445\n",
      "Epoch: 0089 cost = 0.000849\n",
      "Epoch: 0090 cost = 0.000678\n",
      "Epoch: 0091 cost = 0.003224\n",
      "Epoch: 0092 cost = 0.001275\n",
      "Epoch: 0093 cost = 0.000626\n",
      "Epoch: 0094 cost = 0.000122\n",
      "Epoch: 0095 cost = 0.000874\n",
      "Epoch: 0096 cost = 0.000546\n",
      "Epoch: 0097 cost = 0.000205\n",
      "Epoch: 0098 cost = 0.000645\n",
      "Epoch: 0099 cost = 0.001501\n",
      "Epoch: 0100 cost = 0.000596\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "input_batch, output_batch, target_batch = make_batch(\n",
    "    seq_data)\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    _, loss = sess.run(\n",
    "        [optimizer, cost], feed_dict={\n",
    "            enc_input: input_batch, \n",
    "            dec_input: output_batch, \n",
    "            targets: target_batch})\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'cost =', '{:.6f}'.format(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(word):\n",
    "    seq_data = [word, 'P' * len(word)]\n",
    "    i_batch, o_batch, t_batch = make_batch([seq_data])\n",
    "\n",
    "    prediction = tf.argmax(model, 2)\n",
    "    result = sess.run(prediction,\n",
    "                      feed_dict={enc_input: i_batch,\n",
    "                                 dec_input: o_batch,\n",
    "                                 targets: t_batch})\n",
    "\n",
    "    decoded = [char_arr[i] for i in result[0]]\n",
    "    end = decoded.index('E')\n",
    "    translated = ''.join(decoded[:end])\n",
    "    return translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word -> 단어\n",
      "wodr -> 나무\n",
      "love -> 사랑\n",
      "loev -> 사랑\n",
      "abcd -> 소랑\n"
     ]
    }
   ],
   "source": [
    "print('word ->', translate('word'))\n",
    "print('wodr ->', translate('wodr'))\n",
    "print('love ->', translate('love'))\n",
    "print('loev ->', translate('loev'))\n",
    "print('abcd ->', translate('abcd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
