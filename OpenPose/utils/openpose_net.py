# -*- coding: utf-8 -*-
"""openpose_net.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pltq4eMG2H-0IrJXxbxkcTl6D5oqqIdD

# OPENPOSE

- consists of 7 modules: feature module, 6 stage modules
1. Feature module (VGG-19): 3x368x368 -> 128x46x46
2. Stage1: 128x46x46 -> PAFs(38x46x46) and heatmap(19x46x46)
3. stage2 ~ stage6: featuremap + PAFs + heatmap (185x46x46) ->  PAFs(38x46x46) and heatmap(19x46x46)
"""

import torch
import torch.nn as nn
from torch.nn import init
import torchvision

class OpenPoseNet(nn.Module):
  def __init__(self):
    super(OpenPoseNet, self).__init__()

    # feature module
    self.model0 = OpenPose_Feature()

    # stage 1-6
    #PAFs
    self.model1_1 = make_OpenPose_block('block1_1')
    self.model2_1 = make_OpenPose_block('block2_1')
    self.model3_1 = make_OpenPose_block('block3_1')
    self.model4_1 = make_OpenPose_block('block4_1')
    self.model5_1 = make_OpenPose_block('block5_1')
    self.model6_1 = make_OpenPose_block('block6_1')


    # confidence heatmap
    self.model1_2 = make_OpenPose_block('block1_2')
    self.model2_2 = make_OpenPose_block('block2_2')
    self.model3_2 = make_OpenPose_block('block3_2')
    self.model4_2 = make_OpenPose_block('block4_2')
    self.model5_2 = make_OpenPose_block('block5_2')
    self.model6_2 = make_OpenPose_block('block6_2')


  def forward(self, x):
    # input: x

    # feature module
    out1 = self.model0(x)

    # stage1
    out1_1 = self.model1_1(out1) #PAFs
    out1_2 = self.model1_2(out1) # confidence heatmap

    # stage2
    out2 = torch.cat([out1_1, out1_2, out1], 1) # add channels: 185x46x46
    out2_1 = self.model2_1(out2)
    out2_2 = self.model2_2(out2)

    # stage3 
    out3 = torch.cat([out2_1, out2_2, out1], 1) 
    out3_1 = self.model3_1(out3)
    out3_2 = self.model3_2(out3)

    # stage4
    out4 = torch.cat([out3_1, out3_2, out1], 1) 
    out4_1 = self.model4_1(out4)
    out4_2 = self.model4_2(out4)

    # stage4
    out5 = torch.cat([out4_1, out4_2, out1], 1) 
    out5_1 = self.model5_1(out5)
    out5_2 = self.model5_2(out5)

    # stage4
    out6 = torch.cat([out5_1, out5_2, out1], 1) 
    out6_1 = self.model6_1(out6)
    out6_2 = self.model6_2(out6)

    # save the output from each stages
    saved_for_loss = []
    saved_for_loss.append(out1_1) #PAFs loss
    saved_for_loss.append(out1_2) #Confidence Heatmap loss
    saved_for_loss.append(out2_1)
    saved_for_loss.append(out2_2)
    saved_for_loss.append(out3_1)
    saved_for_loss.append(out3_2)
    saved_for_loss.append(out4_1)
    saved_for_loss.append(out4_2)
    saved_for_loss.append(out5_1)
    saved_for_loss.append(out5_2)
    saved_for_loss.append(out6_1)
    saved_for_loss.append(out6_2)

    return (out6_1, out6_2), saved_for_loss

"""# Implementation: Feature module

- VGG-19
"""

class OpenPose_Feature(nn.Module):
  def __init__(self):
    super(OpenPose_Feature, self).__init__()

    # use the 10 convolutional layer from VGG-19 (including Relu and Pooling layer: total 23 layers)
    vgg19 = torchvision.models.vgg19(pretrained= True)
    model = {}
    model['block0'] = vgg19.features[:23] # 10 convolutional layer from VGG-19

    # add new two more convolutional layers 
    model['block0'].add_module("23", torch.nn.Conv2d(512, 256, kernel_size=3, stride = 1, padding = 1))
    model['block0'].add_module("24", torch.nn.ReLU(inplace = True))
    model['block0'].add_module("25", torch.nn.Conv2d(256, 128, kernel_size=3, stride =1, padding=1))
    model['block0'].add_module("26", torch.nn.ReLU(inplace = True))

    self.model = model['block0']

  def forward(self, x):
    output = self.model(x)
    return output

"""# Stage Module Implementation

- stage 1: C3+R -> C3+R -> C3+R -> C1+R(512) -> C1 -> PAFs(38x46x46) or heatmap(19x46x46) 

- stage 2~6: C7+R -> C7+R -> C7+R -> C7+R -> C7+R -> C7+R -> C1 -> PAFs(38x46x46) or heatmap(19x46x46) : # of filters does not change 
"""

def make_OpenPose_block(block_name):
  # make module dict
  blocks = {}

  # stage1 [input_size, output_size, kernel_size, stride, padding]
  blocks['block1_1'] = [{'conv5_1_CPM_L1':[128,128,3,1,1]},
                        {'conv5_2_CPM_L1':[128,128,3,1,1]},
                        {'conv5_3_CPM_L1':[128,128,3,1,1]},
                        {'conv5_4_CPM_L1':[128,512,1,1,0]},
                        {'conv5_5_CPM_L1':[512,38,1,1,0]}] # PAFs

  blocks['block1_2'] = [{'conv5_1_CPM_L2':[128,128,3,1,1]},
                        {'conv5_2_CPM_L2':[128,128,3,1,1]},
                        {'conv5_3_CPM_L2':[128,128,3,1,1]},
                        {'conv5_4_CPM_L2':[128,512,1,1,0]},
                        {'conv5_5_CPM_L2':[512,19,1,1,0]}] # Confidence Heatmap

  # stage2~6
  for i in range(2,7):
    blocks['block%d_1' % i] = [
      {'Mconv1_stage%d_L1' % i : [185, 128, 7, 1, 3]},
      {'Mconv2_stage%d_L1' % i : [128, 128, 7, 1, 3]},
      {'Mconv3_stage%d_L1' % i : [128, 128, 7, 1, 3]},
      {'Mconv4_stage%d_L1' % i : [128, 128, 7, 1, 3]},
      {'Mconv5_stage%d_L1' % i : [128, 128, 7, 1, 3]},
      {'Mconv6_stage%d_L1' % i : [128, 128, 1, 1, 0]},
      {'Mconv7_stage%d_L1' % i : [128, 38, 1, 1, 0]},
    ]

    blocks['block%d_2' % i] = [
      {'Mconv1_stage%d_L2' % i : [185, 128, 7, 1, 3]},
      {'Mconv2_stage%d_L2' % i : [128, 128, 7, 1, 3]},
      {'Mconv3_stage%d_L2' % i : [128, 128, 7, 1, 3]},
      {'Mconv4_stage%d_L2' % i : [128, 128, 7, 1, 3]},
      {'Mconv5_stage%d_L2' % i : [128, 128, 7, 1, 3]},
      {'Mconv6_stage%d_L2' % i : [128, 128, 1, 1, 0]},
      {'Mconv7_stage%d_L2' % i : [128, 19, 1, 1, 0]},
    ]

  # load value of blocks[block_name]
  layer_dict = blocks[block_name]

  layers = []

  for i in range(len(layer_dict)):
    for key, val in layer_dict[i].items():
      if 'pool' in key:
        layers += [nn.MaxPool2d(kernel_size = val[0], stride = val[1], padding = val[2])]

      else:
        conv2d = nn.Conv2d(in_channels=val[0], out_channels=val[1], kernel_size=val[2], stride=val[3], padding=val[4])
        layers += [conv2d, nn.ReLU(inplace = True)]


  # nn.Sequential: layers
  net = nn.Sequential(*layers[:-1]) # for the last layer: we do not need 'ReLu'

  # initialize weight
  def _init_weights_norm(self):
    
    for m in self.modules():
      if isinstance(m, nn.Conv2d):
        init.normal_(m.weight, std = 0.01)

        if m.bias is not None:
          init.constant_(m.bias, 0.0)

  net.apply(_init_weights_norm)

  return net

'''
# test model

net = OpenPoseNet()
net.train()

# create image data
batch_size = 2
new_img = torch.rand(batch_size, 3, 368, 368)

# output
out = net(new_img)
print(out)
'''

