{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"import_modules.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM8m5lAghab+PlqJDdYU7ya"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NtBNHcQJwgLn","executionInfo":{"status":"ok","timestamp":1652169792137,"user_tz":300,"elapsed":13381,"user":{"displayName":"Ko Ahla","userId":"15480385926008847010"}},"outputId":"fb630263-fa67-44cb-cffb-34694b780044"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# google mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["root_dir = '/content/drive/MyDrive/data/'"],"metadata":{"id":"JacC9uLHwiMW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/utils"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sy7tfcLnwiTR","executionInfo":{"status":"ok","timestamp":1652169794625,"user_tz":300,"elapsed":129,"user":{"displayName":"Ko Ahla","userId":"15480385926008847010"}},"outputId":"718c6b06-0b23-41e2-b872-0aab4c06c961"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/utils\n"]}]},{"cell_type":"code","source":["from google.colab import files\n","files.upload()"],"metadata":{"colab":{"resources":{"http://localhost:8080/nbextensions/google.colab/files.js":{"data":"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","ok":true,"headers":[["content-type","application/javascript"]],"status":200,"status_text":""}},"base_uri":"https://localhost:8080/","height":110},"id":"_nvzlNfvws5c","executionInfo":{"status":"ok","timestamp":1652169802928,"user_tz":300,"elapsed":7337,"user":{"displayName":"Ko Ahla","userId":"15480385926008847010"}},"outputId":"a62e6d04-c844-499a-c173-18014a812767"},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-ad66055c-8ad9-41dd-8f2a-64e130ca02ae\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-ad66055c-8ad9-41dd-8f2a-64e130ca02ae\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script src=\"/nbextensions/google.colab/files.js\"></script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving decode_pose.py to decode_pose.py\n"]},{"output_type":"execute_result","data":{"text/plain":["{'decode_pose.py': b'# -*- coding: utf-8 -*-\\n\"\"\"decode_pose.ipynb\\n\\nAutomatically generated by Colaboratory.\\n\\nOriginal file is located at\\n    https://colab.research.google.com/drive/1vdeEwa6Q2bX42toKtDyYZFEGyw3hSCwy\\n\"\"\"\\n\\nimport math\\nimport cv2\\nimport matplotlib.cm\\nimport numpy as np\\nfrom scipy.ndimage.filters import gaussian_filter, maximum_filter\\nfrom scipy.ndimage.morphology import generate_binary_structure\\n\\n# It is better to use 0.1 as threshold when evaluation, but 0.3 for demo\\n# purpose.\\ncmap = matplotlib.cm.get_cmap(\\'hsv\\')\\n\\n# Heatmap indices to find each limb (joint connection). Eg: limb_type=1 is\\n# Neck->LShoulder, so joint_to_limb_heatmap_relationship[1] represents the\\n# indices of heatmaps to look for joints: neck=1, LShoulder=5\\njoint_to_limb_heatmap_relationship = [\\n    [1, 2], [1, 5], [2, 3], [3, 4], [5, 6], [6, 7], [1, 8], [8, 9], [9, 10],\\n    [1, 11], [11, 12], [12, 13], [1, 0], [0, 14], [14, 16], [0, 15], [15, 17],\\n    [2, 16], [5, 17]]\\n\\n# PAF indices containing the x and y coordinates of the PAF for a given limb.\\n# Eg: limb_type=1 is Neck->LShoulder, so\\n# PAFneckLShoulder_x=paf_xy_coords_per_limb[1][0] and\\n# PAFneckLShoulder_y=paf_xy_coords_per_limb[1][1]\\npaf_xy_coords_per_limb = [\\n    [12, 13], [20, 21], [14, 15], [16, 17], [22, 23],\\n    [24, 25], [0, 1], [2, 3], [4, 5], [6, 7], [8, 9], [10, 11], [28, 29],\\n    [30, 31], [34, 35], [32, 33], [36, 37], [18, 19], [26, 27]]\\n\\n# Color code used to plot different joints and limbs (eg: joint_type=3 and\\n# limb_type=3 will use colors[3])\\ncolors = [\\n    [255, 0, 0], [255, 85, 0], [255, 170, 0], [255, 255, 0], [170, 255, 0],\\n    [85, 255, 0], [0, 255, 0], [0, 255, 85], [0, 255, 170], [0, 255, 255],\\n    [0, 170, 255], [0, 85, 255], [0, 0, 255], [85, 0, 255], [170, 0, 255],\\n    [255, 0, 255], [255, 0, 170], [255, 0, 85], [255, 0, 0]]\\n\\nNUM_JOINTS = 18\\nNUM_LIMBS = len(joint_to_limb_heatmap_relationship)\\n\\n\\ndef find_peaks(param, img):\\n    \"\"\"\\n    Given a (grayscale) image, find local maxima whose value is above a given\\n    threshold (param[\\'thre1\\'])\\n    :param img: Input image (2d array) where we want to find peaks\\n    :return: 2d np.array containing the [x,y] coordinates of each peak found\\n    in the image\\n    \"\"\"\\n\\n    peaks_binary = (maximum_filter(img, footprint=generate_binary_structure(\\n        2, 1)) == img) * (img > param[\\'thre1\\'])\\n    # Note reverse ([::-1]): we return [[x y], [x y]...] instead of [[y x], [y\\n    # x]...]\\n    return np.array(np.nonzero(peaks_binary)[::-1]).T\\n\\n\\ndef compute_resized_coords(coords, resizeFactor):\\n    \"\"\"\\n    Given the index/coordinates of a cell in some input array (e.g. image),\\n    provides the new coordinates if that array was resized by making it\\n    resizeFactor times bigger.\\n    E.g.: image of size 3x3 is resized to 6x6 (resizeFactor=2), we\\'d like to\\n    know the new coordinates of cell [1,2] -> Function would return [2.5,4.5]\\n    :param coords: Coordinates (indices) of a cell in some input array\\n    :param resizeFactor: Resize coefficient = shape_dest/shape_source. E.g.:\\n    resizeFactor=2 means the destination array is twice as big as the\\n    original one\\n    :return: Coordinates in an array of size\\n    shape_dest=resizeFactor*shape_source, expressing the array indices of the\\n    closest point to \\'coords\\' if an image of size shape_source was resized to\\n    shape_dest\\n    \"\"\"\\n\\n    # 1) Add 0.5 to coords to get coordinates of center of the pixel (e.g.\\n    # index [0,0] represents the pixel at location [0.5,0.5])\\n    # 2) Transform those coordinates to shape_dest, by multiplying by resizeFactor\\n    # 3) That number represents the location of the pixel center in the new array,\\n    # so subtract 0.5 to get coordinates of the array index/indices (revert\\n    # step 1)\\n    return (np.array(coords, dtype=float) + 0.5) * resizeFactor - 0.5\\n\\n\\ndef NMS(param, heatmaps, upsampFactor=1., bool_refine_center=True, bool_gaussian_filt=False):\\n    \"\"\"\\n    NonMaximaSuppression: find peaks (local maxima) in a set of grayscale images\\n    :param heatmaps: set of grayscale images on which to find local maxima (3d np.array,\\n    with dimensions image_height x image_width x num_heatmaps)\\n    :param upsampFactor: Size ratio between CPM heatmap output and the input image size.\\n    Eg: upsampFactor=16 if original image was 480x640 and heatmaps are 30x40xN\\n    :param bool_refine_center: Flag indicating whether:\\n     - False: Simply return the low-res peak found upscaled by upsampFactor (subject to grid-snap)\\n     - True: (Recommended, very accurate) Upsample a small patch around each low-res peak and\\n     fine-tune the location of the peak at the resolution of the original input image\\n    :param bool_gaussian_filt: Flag indicating whether to apply a 1d-GaussianFilter (smoothing)\\n    to each upsampled patch before fine-tuning the location of each peak.\\n    :return: a NUM_JOINTS x 4 np.array where each row represents a joint type (0=nose, 1=neck...)\\n    and the columns indicate the {x,y} position, the score (probability) and a unique id (counter)\\n    \"\"\"\\n    # MODIFIED BY CARLOS: Instead of upsampling the heatmaps to heatmap_avg and\\n    # then performing NMS to find peaks, this step can be sped up by ~25-50x by:\\n    # (9-10ms [with GaussFilt] or 5-6ms [without GaussFilt] vs 250-280ms on RoG\\n    # 1. Perform NMS at (low-res) CPM\\'s output resolution\\n    # 1.1. Find peaks using scipy.ndimage.filters.maximum_filter\\n    # 2. Once a peak is found, take a patch of 5x5 centered around the peak, upsample it, and\\n    # fine-tune the position of the actual maximum.\\n    #  \\'-> That\\'s equivalent to having found the peak on heatmap_avg, but much faster because we only\\n    #      upsample and scan the 5x5 patch instead of the full (e.g.) 480x640\\n\\n    joint_list_per_joint_type = []\\n    cnt_total_joints = 0\\n\\n    # For every peak found, win_size specifies how many pixels in each\\n    # direction from the peak we take to obtain the patch that will be\\n    # upsampled. Eg: win_size=1 -> patch is 3x3; win_size=2 -> 5x5\\n    # (for BICUBIC interpolation to be accurate, win_size needs to be >=2!)\\n    win_size = 2\\n\\n    for joint in range(NUM_JOINTS):\\n        map_orig = heatmaps[:, :, joint]\\n        peak_coords = find_peaks(param, map_orig)\\n        peaks = np.zeros((len(peak_coords), 4))\\n        for i, peak in enumerate(peak_coords):\\n            if bool_refine_center:\\n                x_min, y_min = np.maximum(0, peak - win_size)\\n                x_max, y_max = np.minimum(\\n                    np.array(map_orig.T.shape) - 1, peak + win_size)\\n\\n                # Take a small patch around each peak and only upsample that\\n                # tiny region\\n                patch = map_orig[y_min:y_max + 1, x_min:x_max + 1]\\n                map_upsamp = cv2.resize(\\n                    patch, None, fx=upsampFactor, fy=upsampFactor, interpolation=cv2.INTER_CUBIC)\\n\\n                # Gaussian filtering takes an average of 0.8ms/peak (and there might be\\n                # more than one peak per joint!) -> For now, skip it (it\\'s\\n                # accurate enough)\\n                map_upsamp = gaussian_filter(\\n                    map_upsamp, sigma=3) if bool_gaussian_filt else map_upsamp\\n\\n                # Obtain the coordinates of the maximum value in the patch\\n                location_of_max = np.unravel_index(\\n                    map_upsamp.argmax(), map_upsamp.shape)\\n                # Remember that peaks indicates [x,y] -> need to reverse it for\\n                # [y,x]\\n                location_of_patch_center = compute_resized_coords(\\n                    peak[::-1] - [y_min, x_min], upsampFactor)\\n                # Calculate the offset wrt to the patch center where the actual\\n                # maximum is\\n                refined_center = (location_of_max - location_of_patch_center)\\n                peak_score = map_upsamp[location_of_max]\\n            else:\\n                refined_center = [0, 0]\\n                # Flip peak coordinates since they are [x,y] instead of [y,x]\\n                peak_score = map_orig[tuple(peak[::-1])]\\n            peaks[i, :] = tuple([int(round(x)) for x in compute_resized_coords(\\n                peak_coords[i], upsampFactor) + refined_center[::-1]]) + (peak_score, cnt_total_joints)\\n            cnt_total_joints += 1\\n        joint_list_per_joint_type.append(peaks)\\n\\n    return joint_list_per_joint_type\\n\\n\\ndef find_connected_joints(param, paf_upsamp, joint_list_per_joint_type, num_intermed_pts=10):\\n    \"\"\"\\n    For every type of limb (eg: forearm, shin, etc.), look for every potential\\n    pair of joints (eg: every wrist-elbow combination) and evaluate the PAFs to\\n    determine which pairs are indeed body limbs.\\n    :param paf_upsamp: PAFs upsampled to the original input image resolution\\n    :param joint_list_per_joint_type: See \\'return\\' doc of NMS()\\n    :param num_intermed_pts: Int indicating how many intermediate points to take\\n    between joint_src and joint_dst, at which the PAFs will be evaluated\\n    :return: List of NUM_LIMBS rows. For every limb_type (a row) we store\\n    a list of all limbs of that type found (eg: all the right forearms).\\n    For each limb (each item in connected_limbs[limb_type]), we store 5 cells:\\n    # {joint_src_id,joint_dst_id}: a unique number associated with each joint,\\n    # limb_score_penalizing_long_dist: a score of how good a connection\\n    of the joints is, penalized if the limb length is too long\\n    # {joint_src_index,joint_dst_index}: the index of the joint within\\n    all the joints of that type found (eg: the 3rd right elbow found)\\n    \"\"\"\\n    connected_limbs = []\\n\\n    # Auxiliary array to access paf_upsamp quickly\\n    limb_intermed_coords = np.empty((4, num_intermed_pts), dtype=np.intp)\\n    for limb_type in range(NUM_LIMBS):\\n        # List of all joints of type A found, where A is specified by limb_type\\n        # (eg: a right forearm starts in a right elbow)\\n        joints_src = joint_list_per_joint_type[joint_to_limb_heatmap_relationship[limb_type][0]]\\n        # List of all joints of type B found, where B is specified by limb_type\\n        # (eg: a right forearm ends in a right wrist)\\n        joints_dst = joint_list_per_joint_type[joint_to_limb_heatmap_relationship[limb_type][1]]\\n        if len(joints_src) == 0 or len(joints_dst) == 0:\\n            # No limbs of this type found (eg: no right forearms found because\\n            # we didn\\'t find any right wrists or right elbows)\\n            connected_limbs.append([])\\n        else:\\n            connection_candidates = []\\n            # Specify the paf index that contains the x-coord of the paf for\\n            # this limb\\n            limb_intermed_coords[2, :] = paf_xy_coords_per_limb[limb_type][0]\\n            # And the y-coord paf index\\n            limb_intermed_coords[3, :] = paf_xy_coords_per_limb[limb_type][1]\\n            for i, joint_src in enumerate(joints_src):\\n                # Try every possible joints_src[i]-joints_dst[j] pair and see\\n                # if it\\'s a feasible limb\\n                for j, joint_dst in enumerate(joints_dst):\\n                    # Subtract the position of both joints to obtain the\\n                    # direction of the potential limb\\n                    limb_dir = joint_dst[:2] - joint_src[:2]\\n                    # Compute the distance/length of the potential limb (norm\\n                    # of limb_dir)\\n                    limb_dist = np.sqrt(np.sum(limb_dir**2)) + 1e-8\\n                    limb_dir = limb_dir / limb_dist  # Normalize limb_dir to be a unit vector\\n\\n                    # Linearly distribute num_intermed_pts points from the x\\n                    # coordinate of joint_src to the x coordinate of joint_dst\\n                    limb_intermed_coords[1, :] = np.round(np.linspace(\\n                        joint_src[0], joint_dst[0], num=num_intermed_pts))\\n                    limb_intermed_coords[0, :] = np.round(np.linspace(\\n                        joint_src[1], joint_dst[1], num=num_intermed_pts))  # Same for the y coordinate\\n                    intermed_paf = paf_upsamp[limb_intermed_coords[0, :],\\n                                              limb_intermed_coords[1, :], limb_intermed_coords[2:4, :]].T\\n\\n                    score_intermed_pts = intermed_paf.dot(limb_dir)\\n                    score_penalizing_long_dist = score_intermed_pts.mean(\\n                    ) + min(0.5 * paf_upsamp.shape[0] / limb_dist - 1, 0)\\n                    # Criterion 1: At least 80% of the intermediate points have\\n                    # a score higher than thre2\\n                    criterion1 = (np.count_nonzero(\\n                        score_intermed_pts > param[\\'thre2\\']) > 0.8 * num_intermed_pts)\\n                    # Criterion 2: Mean score, penalized for large limb\\n                    # distances (larger than half the image height), is\\n                    # positive\\n                    criterion2 = (score_penalizing_long_dist > 0)\\n                    if criterion1 and criterion2:\\n                        # Last value is the combined paf(+limb_dist) + heatmap\\n                        # scores of both joints\\n                        connection_candidates.append(\\n                            [i, j, score_penalizing_long_dist, score_penalizing_long_dist + joint_src[2] + joint_dst[2]])\\n\\n            # Sort connection candidates based on their\\n            # score_penalizing_long_dist\\n            connection_candidates = sorted(\\n                connection_candidates, key=lambda x: x[2], reverse=True)\\n            connections = np.empty((0, 5))\\n            # There can only be as many limbs as the smallest number of source\\n            # or destination joints (eg: only 2 forearms if there\\'s 5 wrists\\n            # but 2 elbows)\\n            max_connections = min(len(joints_src), len(joints_dst))\\n            # Traverse all potential joint connections (sorted by their score)\\n            for potential_connection in connection_candidates:\\n                i, j, s = potential_connection[0:3]\\n                # Make sure joints_src[i] or joints_dst[j] haven\\'t already been\\n                # connected to other joints_dst or joints_src\\n                if i not in connections[:, 3] and j not in connections[:, 4]:\\n                    # [joint_src_id, joint_dst_id, limb_score_penalizing_long_dist, joint_src_index, joint_dst_index]\\n                    connections = np.vstack(\\n                        [connections, [joints_src[i][3], joints_dst[j][3], s, i, j]])\\n                    # Exit if we\\'ve already established max_connections\\n                    # connections (each joint can\\'t be connected to more than\\n                    # one joint)\\n                    if len(connections) >= max_connections:\\n                        break\\n            connected_limbs.append(connections)\\n\\n    return connected_limbs\\n\\n\\ndef group_limbs_of_same_person(connected_limbs, joint_list):\\n    \"\"\"\\n    Associate limbs belonging to the same person together.\\n    :param connected_limbs: See \\'return\\' doc of find_connected_joints()\\n    :param joint_list: unravel\\'d version of joint_list_per_joint [See \\'return\\' doc of NMS()]\\n    :return: 2d np.array of size num_people x (NUM_JOINTS+2). For each person found:\\n    # First NUM_JOINTS columns contain the index (in joint_list) of the joints associated\\n    with that person (or -1 if their i-th joint wasn\\'t found)\\n    # 2nd-to-last column: Overall score of the joints+limbs that belong to this person\\n    # Last column: Total count of joints found for this person\\n    \"\"\"\\n    person_to_joint_assoc = []\\n\\n    for limb_type in range(NUM_LIMBS):\\n        joint_src_type, joint_dst_type = joint_to_limb_heatmap_relationship[limb_type]\\n\\n        for limb_info in connected_limbs[limb_type]:\\n            person_assoc_idx = []\\n            for person, person_limbs in enumerate(person_to_joint_assoc):\\n                if person_limbs[joint_src_type] == limb_info[0] or person_limbs[joint_dst_type] == limb_info[1]:\\n                    person_assoc_idx.append(person)\\n\\n            # If one of the joints has been associated to a person, and either\\n            # the other joint is also associated with the same person or not\\n            # associated to anyone yet:\\n            if len(person_assoc_idx) == 1:\\n                person_limbs = person_to_joint_assoc[person_assoc_idx[0]]\\n                # If the other joint is not associated to anyone yet,\\n                if person_limbs[joint_dst_type] != limb_info[1]:\\n                    # Associate it with the current person\\n                    person_limbs[joint_dst_type] = limb_info[1]\\n                    # Increase the number of limbs associated to this person\\n                    person_limbs[-1] += 1\\n                    # And update the total score (+= heatmap score of joint_dst\\n                    # + score of connecting joint_src with joint_dst)\\n                    person_limbs[-2] += joint_list[limb_info[1]\\n                                                   .astype(int), 2] + limb_info[2]\\n            elif len(person_assoc_idx) == 2:  # if found 2 and disjoint, merge them\\n                person1_limbs = person_to_joint_assoc[person_assoc_idx[0]]\\n                person2_limbs = person_to_joint_assoc[person_assoc_idx[1]]\\n                membership = ((person1_limbs >= 0) & (person2_limbs >= 0))[:-2]\\n                if not membership.any():  # If both people have no same joints connected, merge them into a single person\\n                    # Update which joints are connected\\n                    person1_limbs[:-2] += (person2_limbs[:-2] + 1)\\n                    # Update the overall score and total count of joints\\n                    # connected by summing their counters\\n                    person1_limbs[-2:] += person2_limbs[-2:]\\n                    # Add the score of the current joint connection to the\\n                    # overall score\\n                    person1_limbs[-2] += limb_info[2]\\n                    person_to_joint_assoc.pop(person_assoc_idx[1])\\n                else:  # Same case as len(person_assoc_idx)==1 above\\n                    person1_limbs[joint_dst_type] = limb_info[1]\\n                    person1_limbs[-1] += 1\\n                    person1_limbs[-2] += joint_list[limb_info[1]\\n                                                    .astype(int), 2] + limb_info[2]\\n            else:  # No person has claimed any of these joints, create a new person\\n                # Initialize person info to all -1 (no joint associations)\\n                row = -1 * np.ones(20)\\n                # Store the joint info of the new connection\\n                row[joint_src_type] = limb_info[0]\\n                row[joint_dst_type] = limb_info[1]\\n                # Total count of connected joints for this person: 2\\n                row[-1] = 2\\n                # Compute overall score: score joint_src + score joint_dst + score connection\\n                # {joint_src,joint_dst}\\n                row[-2] = sum(joint_list[limb_info[:2].astype(int), 2]\\n                              ) + limb_info[2]\\n                person_to_joint_assoc.append(row)\\n\\n    # Delete people who have very few parts connected\\n    people_to_delete = []\\n    for person_id, person_info in enumerate(person_to_joint_assoc):\\n        if person_info[-1] < 3 or person_info[-2] / person_info[-1] < 0.2:\\n            people_to_delete.append(person_id)\\n    # Traverse the list in reverse order so we delete indices starting from the\\n    # last one (otherwise, removing item for example 0 would modify the indices of\\n    # the remaining people to be deleted!)\\n    for index in people_to_delete[::-1]:\\n        person_to_joint_assoc.pop(index)\\n\\n    # Appending items to a np.array can be very costly (allocating new memory, copying over the array, then adding new row)\\n    # Instead, we treat the set of people as a list (fast to append items) and\\n    # only convert to np.array at the end\\n    return np.array(person_to_joint_assoc)\\n\\n\\ndef plot_pose(img_orig, joint_list, person_to_joint_assoc, bool_fast_plot=True, plot_ear_to_shoulder=False):\\n    canvas = img_orig.copy()  # Make a copy so we don\\'t modify the original image\\n\\n    # to_plot is the location of all joints found overlaid on top of the\\n    # original image\\n    to_plot = canvas.copy() if bool_fast_plot else cv2.addWeighted(\\n        img_orig, 0.3, canvas, 0.7, 0)\\n\\n    limb_thickness = 4\\n    # Last 2 limbs connect ears with shoulders and this looks very weird.\\n    # Disabled by default to be consistent with original rtpose output\\n    which_limbs_to_plot = NUM_LIMBS if plot_ear_to_shoulder else NUM_LIMBS - 2\\n    for limb_type in range(which_limbs_to_plot):\\n        for person_joint_info in person_to_joint_assoc:\\n            joint_indices = person_joint_info[joint_to_limb_heatmap_relationship[limb_type]].astype(\\n                int)\\n            if -1 in joint_indices:\\n                # Only draw actual limbs (connected joints), skip if not\\n                # connected\\n                continue\\n            # joint_coords[:,0] represents Y coords of both joints;\\n            # joint_coords[:,1], X coords\\n            joint_coords = joint_list[joint_indices, 0:2]\\n\\n            for joint in joint_coords:  # Draw circles at every joint\\n                cv2.circle(canvas, tuple(joint[0:2].astype(\\n                    int)), 4, (255, 255, 255), thickness=-1)\\n            # mean along the axis=0 computes meanYcoord and meanXcoord -> Round\\n            # and make int to avoid errors\\n            coords_center = tuple(\\n                np.round(np.mean(joint_coords, 0)).astype(int))\\n            # joint_coords[0,:] is the coords of joint_src; joint_coords[1,:]\\n            # is the coords of joint_dst\\n            limb_dir = joint_coords[0, :] - joint_coords[1, :]\\n            limb_length = np.linalg.norm(limb_dir)\\n            # Get the angle of limb_dir in degrees using atan2(limb_dir_x,\\n            # limb_dir_y)\\n            angle = math.degrees(math.atan2(limb_dir[1], limb_dir[0]))\\n\\n            # For faster plotting, just plot over canvas instead of constantly\\n            # copying it\\n            cur_canvas = canvas if bool_fast_plot else canvas.copy()\\n            polygon = cv2.ellipse2Poly(\\n                coords_center, (int(limb_length / 2), limb_thickness), int(angle), 0, 360, 1)\\n            cv2.fillConvexPoly(cur_canvas, polygon, colors[limb_type])\\n            if not bool_fast_plot:\\n                canvas = cv2.addWeighted(canvas, 0.4, cur_canvas, 0.6, 0)\\n\\n    return to_plot, canvas\\n\\n\\ndef decode_pose(img_orig, heatmaps, pafs):\\n    param = {\\'thre1\\': 0.1, \\'thre2\\': 0.05, \\'thre3\\': 0.5}\\n\\n    # Bottom-up approach:\\n    # Step 1: find all joints in the image (organized by joint type: [0]=nose,\\n    # [1]=neck...)\\n    joint_list_per_joint_type = NMS(param,\\n                                    heatmaps, img_orig.shape[0] / float(heatmaps.shape[0]))\\n    # joint_list is an unravel\\'d version of joint_list_per_joint, where we add\\n    # a 5th column to indicate the joint_type (0=nose, 1=neck...)\\n    joint_list = np.array([tuple(peak) + (joint_type,) for joint_type,\\n                           joint_peaks in enumerate(joint_list_per_joint_type) for peak in joint_peaks])\\n\\n    # Step 2: find which joints go together to form limbs (which wrists go\\n    # with which elbows)\\n    paf_upsamp = cv2.resize(\\n        pafs, (img_orig.shape[1], img_orig.shape[0]), interpolation=cv2.INTER_CUBIC)\\n    connected_limbs = find_connected_joints(param,\\n                                            paf_upsamp, joint_list_per_joint_type)\\n\\n    # Step 3: associate limbs that belong to the same person\\n    person_to_joint_assoc = group_limbs_of_same_person(\\n        connected_limbs, joint_list)\\n\\n    # (Step 4): plot results\\n    to_plot, canvas = plot_pose(img_orig, joint_list, person_to_joint_assoc)\\n\\n    return to_plot, canvas, joint_list, person_to_joint_assoc\\n\\n'}"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YA5UzTmhwus5","executionInfo":{"status":"ok","timestamp":1652169807030,"user_tz":300,"elapsed":112,"user":{"displayName":"Ko Ahla","userId":"15480385926008847010"}},"outputId":"c64189f6-ad0f-4fc0-f7ef-b25541a9925d"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["import utils.dataloader"],"metadata":{"id":"JIJOAzE3wys7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import utils.data_augmentation"],"metadata":{"id":"ofVLFrezxK3T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import utils.decode_pose"],"metadata":{"id":"UnruHT7qTItb","executionInfo":{"status":"ok","timestamp":1652169839998,"user_tz":300,"elapsed":726,"user":{"displayName":"Ko Ahla","userId":"15480385926008847010"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"HsTRApSz_xGl"},"execution_count":null,"outputs":[]}]}