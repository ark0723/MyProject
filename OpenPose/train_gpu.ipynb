{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_gpu.ipynb","provenance":[{"file_id":"1CQ3DOTcGa0URUtMof6MGWgQHRzDO1MKh","timestamp":1652170974895}],"collapsed_sections":[],"authorship_tag":"ABX9TyO6ztaWlHcW9HcK3k56h2pp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Tv8zogN2yGZ","executionInfo":{"status":"ok","timestamp":1652171252502,"user_tz":300,"elapsed":668,"user":{"displayName":"Ko Ahla","userId":"15480385926008847010"}},"outputId":"b2c080b7-3c1a-4cca-8451-ebe49d7dc8fc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["# google mount drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%cd /content/drive/MyDrive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K0m1hyj43Ht-","executionInfo":{"status":"ok","timestamp":1652171252503,"user_tz":300,"elapsed":6,"user":{"displayName":"Ko Ahla","userId":"15480385926008847010"}},"outputId":"57e07e7c-260e-463d-9d2e-98221214a56b"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["# import libraries\n","import random\n","import math\n","import time\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.utils.data as data\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from utils.dataloader import make_datapath_list, DataTransform, COCOkeypointsDataset\n","# to get the same result everytime, set seeds\n","torch.manual_seed(1234)\n","np.random.seed(1234)\n","random.seed(1234) "],"metadata":{"id":"ia_1LwS_4q7C","executionInfo":{"status":"ok","timestamp":1652171256748,"user_tz":300,"elapsed":4250,"user":{"displayName":"Ko Ahla","userId":"15480385926008847010"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# MSCOCO file directory list\n","\n","root_dir = '/content/drive/MyDrive/data/'\n","train_img_list, train_mask_list, val_img_list, val_mask_list, train_meta_list, val_meta_list = make_datapath_list(rootpath = root_dir)"],"metadata":{"id":"F6_ZdAQpL2_H","executionInfo":{"status":"ok","timestamp":1652171277774,"user_tz":300,"elapsed":21029,"user":{"displayName":"Ko Ahla","userId":"15480385926008847010"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["'''\n","idx_list = [i for i in range(len(val_img_list))]\n","# sampling (k=100)\n","idx = random.sample(idx_list, k=100)\n","\n","\n","# Python3 program to Find elements of a \n","# list by indices present in another list\n","  \n","def findElements(lst, idx):\n","    return list(map(lst.__getitem__, idx))\n","            \n","# sampled list\n","val_img_list = findElements(val_img_list, idx)\n","val_mask_list = findElements(val_mask_list, idx)\n","val_meta_list = findElements(val_meta_list, idx)\n","'''"],"metadata":{"id":"-72JXYOGL_pU","executionInfo":{"status":"ok","timestamp":1652171277774,"user_tz":300,"elapsed":16,"user":{"displayName":"Ko Ahla","userId":"15480385926008847010"}},"colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"8f5f67ad-32c7-408d-fd69-e8cb5e32066b"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nidx_list = [i for i in range(len(val_img_list))]\\n# sampling (k=100)\\nidx = random.sample(idx_list, k=100)\\n\\n\\n# Python3 program to Find elements of a \\n# list by indices present in another list\\n  \\ndef findElements(lst, idx):\\n    return list(map(lst.__getitem__, idx))\\n            \\n# sampled list\\nval_img_list = findElements(val_img_list, idx)\\nval_mask_list = findElements(val_mask_list, idx)\\nval_meta_list = findElements(val_meta_list, idx)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# dataset : because oritinal training set is too huge, then we will use validatoin set as our training data\n","train_set = COCOkeypointsDataset(val_img_list, val_mask_list, val_meta_list, phase = 'train', transform=DataTransform())\n","#train_set = COCOkeypointsDataset(train_img_list, train_mask_list, train_meta_list, phase = 'train', transform=DataTransform())\n","\n","# we do not implement validation for this experiment\n","# val_set = COCOkeypointsDataset(val_img_list, val_mask_list, val_meta_list, phase = 'val', transform=DataTransform())\n","\n","\n","# set DataLoader\n","batch_size = 32\n","\n","train_dataloader = data.DataLoader(train_set, batch_size=batch_size, shuffle = True)\n","#val_dataloader = data.DataLoader(val_set, batch_size=batch_size, shuffle = False)\n","\n","dataloaders_dict = {\"train\": train_dataloader, \"val\": None}"],"metadata":{"id":"RGcnSUFE3WFF","executionInfo":{"status":"ok","timestamp":1652171277774,"user_tz":300,"elapsed":6,"user":{"displayName":"Ko Ahla","userId":"15480385926008847010"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["# Loss Funtion\n","- for every pixel, regression error b/w ground truth of annotation and (PAFs and Confidence Heatmap) -> MSE loss\n","- Note: if there's no annotation for visible object in image, we do not calculate loss for the part. (use 'mask' - No loss: 0, loss:1)  "],"metadata":{"id":"hXbboCAq6H22"}},{"cell_type":"code","source":["# loss function\n","\n","class OpenPoseLoss(nn.Module):\n","\n","  def __init__(self):\n","    super(OpenPoseLoss, self).__init__()\n","  \n","  def forward(self, saved_for_loss, heatmap_target, heat_mask, paf_target, paf_mask):\n","    '''\n","    parameters\n","    1. saved_for_loss : OpenPoseNet output(list)\n","    2. heatmap_target: [num_batch, 19, 46, 46] - body part annotation info\n","    3. heatmap_mask: [num_batch, 19, 46, 46] - heatmap image mask\n","    4. paf_target: [num_batch, 38, 46, 46] - PAF's ground truth info\n","    5. paf_mask: [num_batch, 38, 46, 46] - PAF mask image\n","\n","    Return: loss \n","\n","    # save the output from each stages (OpenPoseNet Code)\n","    saved_for_loss = []\n","    saved_for_loss.append(out1_1) #PAFs loss\n","    saved_for_loss.append(out1_2) #Confidence Heatmap loss\n","    saved_for_loss.append(out2_1)\n","    saved_for_loss.append(out2_2)\n","    saved_for_loss.append(out3_1)\n","    saved_for_loss.append(out3_2)\n","    saved_for_loss.append(out4_1)\n","    saved_for_loss.append(out4_2)\n","    saved_for_loss.append(out5_1)\n","    saved_for_loss.append(out5_2)\n","    saved_for_loss.append(out6_1)\n","    saved_for_loss.append(out6_2)\n","    '''\n","\n","    total_loss = 0\n","\n","    for i in range(6): # six stage\n","      # by multipying paf_mask(0 or 1) and heat_mask(0 or 1), example, if paf_mask =0, then we do not calculate loss \n","      #PAFs\n","      pred1 = saved_for_loss[2*i]*paf_mask\n","      true1 = paf_target.float()*paf_mask\n","\n","      #confidence heatmap\n","      pred2 = saved_for_loss[2*1 + 1]*heat_mask\n","      true2 = heatmap_target.float()*heat_mask\n","\n","      total_loss += F.mse_loss(pred1,true1, reduction = 'mean') + F.mse_loss(pred2, true2, reduction= 'mean')\n","\n","    return total_loss"],"metadata":{"id":"8GqC8XX152NB","executionInfo":{"status":"ok","timestamp":1652171277775,"user_tz":300,"elapsed":6,"user":{"displayName":"Ko Ahla","userId":"15480385926008847010"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def train(net, dataloaders_dict, loss, optimizer, num_epochs):\n","\n","  # check if GPU is availabe\n","  device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","  print(\"device: \", device)\n","\n","  # network feed to GPU\n","  net.to(device)\n","\n","  # input image size has the fixed size -> runtime can be faster after cudnn tuned  \n","  torch.backends.cudnn.benchmark = True\n","\n","  # image parameter\n","  num_train_imgs = len(dataloaders_dict['train'].dataset)\n","  batch_size = dataloaders_dict['train'].batch_size\n","\n","  iter = 1\n","\n","  # for loop - every epoch\n","  for epoch in range(num_epochs):\n","\n","    # save start time\n","    t_epoch_start = time.time()\n","    t_iter_start = time.time()\n","    epoch_train_loss = 0\n","    epoch_val_loss = 0\n","\n","    print(\"=\"*50)\n","    print(\"Epoch {}/{}\".format(epoch + 1, num_epochs))\n","    print(\"=\"*50)\n","\n","    for phase in ['train', 'val']:\n","      if phase == 'train':\n","        net.train()\n","        optimizer.zero_grad()\n","        print(' (train) ')\n","\n","      else:\n","        continue\n","        # net.eval()\n","        # print(\"=\"*50)\n","        # print(' (val) ')\n","\n","      # mini-batch \n","      for img, heatmap_target, heat_mask, paf_target, paf_mask in dataloaders_dict[phase]:\n","        # if mini-batch size ==1, raise error in pytorch -> continue\n","        if img.size()[0] == 1 :\n","          continue\n","\n","        # if GPU is availabe, data will be forward to GPU\n","        img = img.to(device)\n","        heatmap_target = heatmap_target.to(device)\n","        heat_mask = heat_mask.to(device)\n","        paf_target = paf_target.to(device)\n","        paf_mask = paf_mask.to(device)\n","\n","        # initialize optimizer\n","        optimizer.zero_grad()\n","\n","        # forward propagation\n","        with torch.set_grad_enabled(phase == 'train'):\n","          # network output: (out6_1, out6_2) and saved_for_loss\n","          _, saved_for_loss = net(img)\n","\n","          batch_loss = loss(saved_for_loss, heatmap_target, heat_mask, paf_target, paf_mask)\n","          del saved_for_loss\n","\n","          # when train mode, back-propagation\n","          if phase == 'train':\n","            batch_loss.backward()\n","            optimizer.step()\n","\n","            if (iter % 10 == 0): # every 10 iteration\n","              t_iter_end = time.time()\n","              elapse = t_iter_end - t_iter_start\n","              print('Iteration {} || Loss: {:.4f} || elapsed time: {:.4f}sec.'.format(iter, batch_loss.item()/batch_size, elapse))\n","              t_iter_start = time.time()\n","\n","            epoch_train_loss += batch_loss.item()\n","            iter += 1\n","\n","          # evaluation\n","          # else:\n","            # epoch_val_loss += batch_loss.item()\n","        \n","    t_epoch_end = time.time()\n","    print(\"=\"*50)\n","    print(\"epoch {} || Train Loss: {:.4f} || Validation Loss: {:.4f}\".format(epoch +1, epoch_train_loss/num_train_imgs, 0))\n","    print('elpased time per epoch: {:.4f} sec.'.format(t_epoch_end - t_epoch_start))\n","    t_epoch_start = time.time()\n","\n","  # save network\n","  torch.save(net.state_dict(), '/content/drive/MyDrive/weights/openpose_net_' + str(epoch+1) + '.pth')"],"metadata":{"id":"tb-kIVqKB8m6","executionInfo":{"status":"ok","timestamp":1652171277775,"user_tz":300,"elapsed":6,"user":{"displayName":"Ko Ahla","userId":"15480385926008847010"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["from utils.openpose_net import OpenPoseNet\n","# create network \n","net = OpenPoseNet()\n","\n","# learning setting\n","loss = OpenPoseLoss()\n","opt = optim.SGD(net.parameters(), lr = 1e-2, momentum=0.9, weight_decay=0.0001)\n","num_epochs = 2\n","\n","# train\n","train(net, dataloaders_dict, loss = loss, optimizer = opt, num_epochs = num_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"md-3VZb_BPMi","executionInfo":{"status":"ok","timestamp":1652173455084,"user_tz":300,"elapsed":1988903,"user":{"displayName":"Ko Ahla","userId":"15480385926008847010"}},"outputId":"da5960a6-bf7d-42b9-cf7c-dca6dbcf11f1"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["device:  cuda:0\n","==================================================\n","Epoch 1/2\n","==================================================\n"," (train) \n","Iteration 10 || Loss: 0.0066 || elapsed time: 323.9864sec.\n","Iteration 20 || Loss: 0.0029 || elapsed time: 199.4252sec.\n","Iteration 30 || Loss: 0.0016 || elapsed time: 176.2561sec.\n","Iteration 40 || Loss: 0.0014 || elapsed time: 165.3812sec.\n","Iteration 50 || Loss: 0.0012 || elapsed time: 152.7975sec.\n","Iteration 60 || Loss: 0.0013 || elapsed time: 139.8084sec.\n","==================================================\n","epoch 1 || Train Loss: 0.0030 || Validation Loss: 0.0000\n","elpased time per epoch: 1283.6223 sec.\n","==================================================\n","Epoch 2/2\n","==================================================\n"," (train) \n","Iteration 70 || Loss: 0.0014 || elapsed time: 28.0444sec.\n","Iteration 80 || Loss: 0.0014 || elapsed time: 101.5075sec.\n","Iteration 90 || Loss: 0.0013 || elapsed time: 100.9684sec.\n","Iteration 100 || Loss: 0.0012 || elapsed time: 101.7070sec.\n","Iteration 110 || Loss: 0.0012 || elapsed time: 100.2192sec.\n","Iteration 120 || Loss: 0.0014 || elapsed time: 103.2448sec.\n","Iteration 130 || Loss: 0.0012 || elapsed time: 103.5260sec.\n","==================================================\n","epoch 2 || Train Loss: 0.0014 || Validation Loss: 0.0000\n","elpased time per epoch: 698.2329 sec.\n"]}]},{"cell_type":"markdown","source":["# colab 끊김 방지 (key F12 -> developer mode)\n","-  enter console\n","- typing: \n","- function ClickConnect(){\n","    console.log(\"코랩 연결 끊김 방지\"); \n","    document.querySelector(\"colab-toolbar-button#connect\").click() \n","}\n","setInterval(ClickConnect, 60 * 1000)\n","\n"],"metadata":{"id":"py62-hh8ZdMM"}}]}