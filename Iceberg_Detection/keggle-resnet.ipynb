{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_x = '/home/snu/Downloads/자료 정리/X_v3.txt'\n",
    "input_y = '/home/snu/Downloads/자료 정리/y_v3.txt'\n",
    "\n",
    "image_x = 75\n",
    "image_y = 75\n",
    "image_z = 2\n",
    "\n",
    "No_data = 0\n",
    "\n",
    "y_class = 2\n",
    "\n",
    "Jump = 0.000005\n",
    "\n",
    "Batch_X = 30\n",
    "Batch_Y = 101\n",
    "\n",
    "structure ='''\n",
    "\n",
    "#<<< Structure >>>\n",
    "#v3\n",
    "# Convolution\n",
    "conv(1,2,8)\n",
    "conv(2,8,32, relu=0)\n",
    "conv(3,32,32)\n",
    "conv(4,32,64,relu=0)\n",
    "conv(5,32,64,-2); max_p(2)\n",
    "conv(6,64,64,relu=0)\n",
    "conv(7,64,64,2)\n",
    "conv(8,64,64,relu=0)\n",
    "conv(9,64,64,2)\n",
    "conv(10,64,128,relu=0)\n",
    "conv(11,64,128,-2); max_p(2)\n",
    "conv(12,128,128,relu=0)\n",
    "conv(13,128,128,2)\n",
    "conv(14,128,128,relu=0)\n",
    "conv(15,128,128,2)\n",
    "conv(16,128,256,relu=0)\n",
    "conv(17,128,256,-2); max_p(2)\n",
    "conv(18,256,256,relu=0)\n",
    "conv(19,256,256,2)\n",
    "conv(20,256,256,relu=0)\n",
    "conv(21,256,256,2)\n",
    "conv(22,256,512,relu=0)\n",
    "conv(23,256,512,-2) \n",
    "\n",
    "# Drop out \n",
    "#exec(\"L%s = tf.nn.dropout(L%s,dropout_prob)\" %(last_layer,last_layer))\n",
    "\n",
    "# Fully connected \n",
    "full(24,512,64)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import email_sending\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, 'rb') as fo:\n",
    "        data = pickle.load(fo, encoding='bytes')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the CIFAR-10\n",
    "def load_CIFAR10(pos, n_chunks=1):\n",
    "    Xtr = []\n",
    "    Ytr = []\n",
    "    for i in range(n_chunks):\n",
    "        train = unpickle(pos + '/data_batch_{0}'.format(i + 1))\n",
    "        Xtr.extend(train[b'data'])\n",
    "        Ytr.extend(train[b'labels'])\n",
    "        test = unpickle(pos + '/test_batch')\n",
    "        Xte = test[b'data'] \n",
    "        Yte = test[b'labels']\n",
    "    return np.array(Xtr), np.array(Ytr), np.array(Xte), np.array(Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expresses the label data in one-hot encoding.\n",
    "def onehot_encoding (Ytr, Yte):\n",
    "    Ytr_onehot = np.zeros((Ytr.size, int(y_class)))\n",
    "    Yte_onehot = np.zeros((Yte.size, int(y_class)))\n",
    "    for i in range(Ytr.size):\n",
    "        Ytr_onehot[i][Ytr[i]] = 1\n",
    "    for i in range(Yte.size):\n",
    "        Yte_onehot[i][Yte[i]] = 1\n",
    "    return Ytr_onehot, Yte_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the train and test data\n",
    "a=open(input_x,'r')\n",
    "Xt = []\n",
    "while True:\n",
    "    temp = a.readline()\n",
    "    if temp=='':break\n",
    "    else : exec(\"Xt.append(%s)\" %temp)\n",
    "a.close()\n",
    "\n",
    "a=open(input_y,'r')\n",
    "Yt = []\n",
    "exec(\"Yt=\" +a.readline())\n",
    "a.close()\n",
    "\n",
    "Xt = np.array(Xt) - No_data\n",
    "Yt = np.array(Yt) \n",
    "test_idxs = np.random.permutation(len(Xt))\n",
    "Xt = Xt[test_idxs]\n",
    "Yt = Yt[test_idxs]\n",
    "\n",
    "#Train/Valid Sep\n",
    "TVS = 1200\n",
    "Xtr, Ytr, Xte, Yte = Xt[:TVS],Yt[:TVS],Xt[TVS:],Yt[TVS:]\n",
    "\n",
    "\n",
    "# label data of train and test data, label data is represented by one-hot encoding\n",
    "Ytr_onehot, Yte_onehot = onehot_encoding(Ytr, Yte)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "L0 = tf.placeholder(tf.float32, [None, int(image_x), int(image_y), int(image_z)])\n",
    "Y = tf.placeholder(tf.float32, [None, int(y_class)])\n",
    "dropout_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_layer = 0\n",
    "image_size = int(image_x)\n",
    "last_cha = int(image_z)\n",
    "def max_p(n):\n",
    "    exec(\"global L%s \\nL%s = tf.nn.max_pool(L%s, ksize=[1,n,n,1],strides=[1,n,n,1,],padding='SAME')\" %(last_layer,last_layer,last_layer))\n",
    "    global image_size\n",
    "    image_size = round(image_size/n)\n",
    "    \n",
    "def conv(n, cha_from, cha_to, res=0, relu=1, p=0): \n",
    "    # n:layer번호 / cha_from: 이전 채널 수 / cha_to: 새 채널 수 / res: 양수-only add / relu: relu / p: pool\n",
    "    #exec(\"global L%s\" %n)\n",
    "    global last_cha, last_layer\n",
    "    last_cha =(cha_to)\n",
    "    last_layer = (n)\n",
    "    exec(\"global W%s \\nW%s = tf.Variable(tf.random_normal([3,3,cha_from,cha_to],stddev=0.01))\" %(n,n))\n",
    "    if res == 0:\n",
    "        exec(\"global L%s \\nL%s = tf.nn.conv2d(L%s,W%s,strides=[1,1,1,1],padding='SAME')\" %(n,n,n-1,n))\n",
    "        if relu == 1:\n",
    "            exec(\"global L%s \\nL%s = tf.nn.relu(L%s)\" %(n,n,n))\n",
    "            exec(\"global L%s \\nL%s = tf.contrib.layers.batch_norm(L%s)\" %(n,n,n))\n",
    "\n",
    "    else:\n",
    "        if res > 0:\n",
    "            exec(\"global L%s \\nL%s = tf.add(L%s,L%s)\"   %(n,n,n-res,n-1))\n",
    "            if relu == 1:\n",
    "                exec(\"global L%s \\nL%s = tf.nn.relu(L%s)\" %(n,n,n))\n",
    "                exec(\"global L%s \\nL%s = tf.contrib.layers.batch_norm(L%s)\" %(n,n,n))\n",
    "        else:   \n",
    "            exec(\"global L%s \\nL%s = tf.nn.conv2d(L%s,W%s,strides=[1,1,1,1],padding='SAME')\" %(n,n,n+res,n))\n",
    "            exec(\"global L%s \\ntf.add(L%s,L%s)\"   %(n,n,n-1))\n",
    "            if relu == 1:\n",
    "                exec(\"global L%s \\nL%s = tf.nn.relu(L%s)\" %(n,n,n))\n",
    "                exec(\"global L%s \\nL%s = tf.contrib.layers.batch_norm(L%s)\" %(n,n,n))\n",
    "                \n",
    "def full(n,che_from,che_to):\n",
    "    global last_cha, last_layer,image_size\n",
    "    last_cha =(che_to)\n",
    "    last_layer = (n)\n",
    "    \n",
    "    exec(\"global W%s \\nW%s = tf.Variable(tf.random_normal([%s,%s],stddev=0.01))\" %(n,n,int(image_size*image_size*che_from),int(che_to)))\n",
    "    exec(\"global L%s \\nL%s = tf.reshape(L%s,[-1,%s])\" %(n,n,n-1,(int(image_size*image_size*che_from))))\n",
    "    exec(\"global B%s \\nB%s =  tf.Variable(tf.random_normal([%s],stddev=0.01))\" %(n,n,int(che_to)))\n",
    "    exec(\"global L%s \\nL%s =tf.matmul(L%s,W%s) + B%s \" %(n,n,n,n,n))\n",
    "    exec(\"L%s = tf.nn.relu(L%s)\" %(n,n))\n",
    "    image_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Implement the layers of CNNs ###\n",
    "\n",
    "\n",
    "exec(structure)\n",
    "exec(\"W%s = tf.Variable(tf.random_normal([%s,%s],stddev=0.01))\" %(last_layer+1,int(last_cha),y_class))\n",
    "exec(\"model = tf.matmul(L%s,W%s)\" %(last_layer,last_layer+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function, you can change the implementation\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(Jump).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph():\n",
    "    \n",
    "    img = Image.open('/home/snu/Downloads/blank.png')\n",
    "    draw_img = ImageDraw.Draw(img)\n",
    "\n",
    "    x = 0\n",
    "    acc_min = min(acc_list) ; acc_max = max(acc_list)\n",
    "    cost_min = min(cost_list); cost_max = max(cost_list)\n",
    "    \n",
    "    draw_img.text(xy=(100,70),text=str('ACCURACY'),fill=(0,0,255,255))\n",
    "    draw_img.text(xy=(100,370),text=str('COST'),fill=(0,0,255,255))\n",
    "    for i in range(len(epoch_list)):\n",
    "        x = x + 30 \n",
    "        y = 300 - (float((acc_list[i]-acc_min)/(acc_max-acc_min))*200 )\n",
    "        draw_img.line((x,300,x,y), width=10, fill=(0,0,255,255))\n",
    "        draw_img.text(xy=(x-6,310),text=str(epoch_list[i]),fill=(255,0,0,255))\n",
    "        draw_img.text(xy=(x-10,320),text=str(round(acc_list[i],2)),fill=(0,0,255,255))\n",
    "        \n",
    "        y = 600 - (float((cost_list[i]-cost_min)/(cost_max-cost_min))*200 )\n",
    "        draw_img.line((x,600,x,y), width=10, fill=(0,0,255,255))\n",
    "        draw_img.text(xy=(x-6,610),text=str(epoch_list[i]),fill=(255,0,0,255))\n",
    "        draw_img.text(xy=(x-10,620),text=str(round(cost_list[i],2)),fill=(0,0,255,255))\n",
    "\n",
    "    img.save('/home/snu/Downloads/blank2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0\n",
    "epoch = 0\n",
    "acc_list= []\n",
    "epoch_list = []\n",
    "cost_list = []\n",
    "def accu(sub_info):\n",
    "    global accuracy\n",
    "    test_batch_size = int(Batch_Y)\n",
    "    test_datasize,_,_,_ = Xte.shape\n",
    "    test_total_batch = int(test_datasize / test_batch_size)\n",
    "\n",
    "    test_idxs = np.random.permutation(test_datasize)\n",
    "    Xte_random = Xte[test_idxs]\n",
    "    Yte_random = Yte_onehot[test_idxs]\n",
    "\n",
    "    correctness = tf.equal(tf.argmax(model, 1), tf.argmax(Y,1))\n",
    "    partial_accuracy = tf.reduce_mean(tf.cast(correctness, tf.float32))\n",
    "\n",
    "    accuracy = 0\n",
    "    #print('Partial Accuracies')\n",
    "    for i in range(test_total_batch):\n",
    "        t_batch_X = Xte_random[i * test_batch_size:(i+1) * test_batch_size].reshape(-1,int(image_x),int(image_y),int(image_z))\n",
    "        t_batch_Y = Yte_random[i * test_batch_size:(i+1) * test_batch_size]\n",
    "\n",
    "        p_acc = sess.run(partial_accuracy,\n",
    "            feed_dict={\n",
    "            L0: t_batch_X.reshape(-1, int(image_x), int(image_y), int(image_z)),\n",
    "            Y: t_batch_Y,\n",
    "            dropout_prob: 1})\n",
    "\n",
    "        #print(p_acc)\n",
    "        accuracy += p_acc\n",
    "\n",
    "    accuracy = accuracy / test_total_batch\n",
    "    print('*** Accuracy : {:,.4f} ***'.format(accuracy))\n",
    "    \n",
    "    epoch_list.append(epoch); acc_list.append(accuracy); cost_list.append(avg_cost)\n",
    "    if len(epoch_list) > 20:\n",
    "        epoch_list.pop(0); acc_list.pop(0) ; cost_list.pop(0)\n",
    "    try:graph()\n",
    "    except:pass\n",
    "    \n",
    "    \n",
    "    global best_acc\n",
    "    if accuracy >= 0.75 and accuracy >= best_acc:\n",
    "        best_acc =  accuracy\n",
    "        email_sending.email2me('New Record! '+str(best_acc), sub_info+'\\n'+structure, '/home/snu/Downloads/blank2.png')\n",
    "        email_sending.email2u('New Record! '+str(best_acc), sub_info+'\\n'+structure, '/home/snu/Downloads/blank2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH :  0001 Avg.cost =  0.615\n",
      "*** Accuracy : 0.8094 ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snu/.conda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "/home/snu/.conda/envs/tensorflow/lib/python3.6/site-packages/ipykernel/__main__.py:19: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH :  0002 Avg.cost =  0.482\n",
      "*** Accuracy : 0.8292 ***\n",
      "EPOCH :  0003 Avg.cost =  0.410\n",
      "*** Accuracy : 0.8416 ***\n",
      "EPOCH :  0004 Avg.cost =  0.356\n",
      "*** Accuracy : 0.8515 ***\n",
      "EPOCH :  0005 Avg.cost =  0.312\n",
      "*** Accuracy : 0.8515 ***\n",
      "EPOCH :  0006 Avg.cost =  0.276\n",
      "*** Accuracy : 0.8564 ***\n",
      "EPOCH :  0007 Avg.cost =  0.244\n",
      "*** Accuracy : 0.8614 ***\n",
      "EPOCH :  0008 Avg.cost =  0.215\n",
      "*** Accuracy : 0.8589 ***\n",
      "EPOCH :  0009 Avg.cost =  0.188\n",
      "*** Accuracy : 0.8564 ***\n",
      "EPOCH :  0010 Avg.cost =  0.165\n",
      "*** Accuracy : 0.8639 ***\n",
      "EPOCH :  0011 Avg.cost =  0.143\n",
      "*** Accuracy : 0.8614 ***\n",
      "EPOCH :  0012 Avg.cost =  0.123\n",
      "*** Accuracy : 0.8614 ***\n",
      "EPOCH :  0013 Avg.cost =  0.105\n",
      "*** Accuracy : 0.8614 ***\n",
      "EPOCH :  0014 Avg.cost =  0.089\n",
      "*** Accuracy : 0.8639 ***\n",
      "EPOCH :  0015 Avg.cost =  0.075\n",
      "*** Accuracy : 0.8564 ***\n",
      "EPOCH :  0016 Avg.cost =  0.063\n",
      "*** Accuracy : 0.8663 ***\n",
      "EPOCH :  0017 Avg.cost =  0.053\n",
      "*** Accuracy : 0.8663 ***\n",
      "EPOCH :  0018 Avg.cost =  0.045\n",
      "*** Accuracy : 0.8688 ***\n",
      "EPOCH :  0019 Avg.cost =  0.038\n",
      "*** Accuracy : 0.8738 ***\n",
      "EPOCH :  0020 Avg.cost =  0.032\n",
      "*** Accuracy : 0.8639 ***\n",
      "EPOCH :  0021 Avg.cost =  0.028\n",
      "*** Accuracy : 0.8639 ***\n",
      "EPOCH :  0022 Avg.cost =  0.024\n",
      "*** Accuracy : 0.8663 ***\n",
      "EPOCH :  0023 Avg.cost =  0.020\n",
      "*** Accuracy : 0.8688 ***\n",
      "EPOCH :  0024 Avg.cost =  0.018\n",
      "*** Accuracy : 0.8688 ***\n",
      "EPOCH :  0025 Avg.cost =  0.015\n",
      "*** Accuracy : 0.8663 ***\n",
      "EPOCH :  0026 Avg.cost =  0.014\n",
      "*** Accuracy : 0.8688 ***\n",
      "EPOCH :  0027 Avg.cost =  0.012\n",
      "*** Accuracy : 0.8713 ***\n",
      "EPOCH :  0028 Avg.cost =  0.011\n",
      "*** Accuracy : 0.8688 ***\n",
      "EPOCH :  0029 Avg.cost =  0.009\n",
      "*** Accuracy : 0.8713 ***\n",
      "EPOCH :  0030 Avg.cost =  0.008\n",
      "*** Accuracy : 0.8738 ***\n",
      "EPOCH :  0031 Avg.cost =  0.007\n",
      "*** Accuracy : 0.8589 ***\n",
      "EPOCH :  0032 Avg.cost =  0.007\n",
      "*** Accuracy : 0.8738 ***\n",
      "EPOCH :  0033 Avg.cost =  0.006\n",
      "*** Accuracy : 0.8738 ***\n",
      "EPOCH :  0034 Avg.cost =  0.006\n",
      "*** Accuracy : 0.8738 ***\n",
      "EPOCH :  0035 Avg.cost =  0.005\n",
      "*** Accuracy : 0.8738 ***\n",
      "EPOCH :  0036 Avg.cost =  0.005\n",
      "*** Accuracy : 0.8688 ***\n",
      "EPOCH :  0037 Avg.cost =  0.004\n",
      "*** Accuracy : 0.8762 ***\n",
      "EPOCH :  0038 Avg.cost =  0.004\n",
      "*** Accuracy : 0.8738 ***\n",
      "EPOCH :  0039 Avg.cost =  0.004\n",
      "*** Accuracy : 0.8713 ***\n",
      "EPOCH :  0040 Avg.cost =  0.003\n",
      "*** Accuracy : 0.8614 ***\n",
      "EPOCH :  0041 Avg.cost =  0.003\n",
      "*** Accuracy : 0.8688 ***\n",
      "EPOCH :  0042 Avg.cost =  0.003\n",
      "*** Accuracy : 0.8713 ***\n",
      "EPOCH :  0043 Avg.cost =  0.003\n",
      "*** Accuracy : 0.8713 ***\n",
      "EPOCH :  0044 Avg.cost =  0.003\n",
      "*** Accuracy : 0.8663 ***\n",
      "EPOCH :  0045 Avg.cost =  0.002\n",
      "*** Accuracy : 0.8713 ***\n",
      "EPOCH :  0046 Avg.cost =  0.002\n",
      "*** Accuracy : 0.8738 ***\n",
      "EPOCH :  0047 Avg.cost =  0.002\n",
      "*** Accuracy : 0.8663 ***\n",
      "EPOCH :  0048 Avg.cost =  0.002\n",
      "*** Accuracy : 0.8663 ***\n",
      "EPOCH :  0049 Avg.cost =  0.002\n",
      "*** Accuracy : 0.8713 ***\n",
      "EPOCH :  0050 Avg.cost =  0.002\n",
      "*** Accuracy : 0.8688 ***\n",
      "EPOCH :  0051 Avg.cost =  0.002\n",
      "*** Accuracy : 0.8713 ***\n",
      "EPOCH :  0052 Avg.cost =  0.002\n",
      "*** Accuracy : 0.8713 ***\n",
      "EPOCH :  0053 Avg.cost =  0.001\n",
      "*** Accuracy : 0.8688 ***\n",
      "EPOCH :  0054 Avg.cost =  0.001\n",
      "*** Accuracy : 0.8663 ***\n",
      "EPOCH :  0055 Avg.cost =  0.001\n",
      "*** Accuracy : 0.8688 ***\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9fab2a54bb29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         _,curr_loss = sess.run([optimizer,cost],   \n\u001b[0;32m---> 15\u001b[0;31m                               feed_dict ={L0:batch_xs,Y:batch_ys,dropout_prob:0.7})\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mtotal_cost\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcurr_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    787\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 789\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    790\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    995\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 997\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    998\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1130\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1132\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1133\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1137\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/tensorflow/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Implement the train process ###\n",
    "batch_size= int(Batch_X)\n",
    "total_batch = int(len(Xtr)/batch_size)\n",
    "\n",
    "off_switch = 0\n",
    "while True:\n",
    "    \n",
    "    epoch += 1\n",
    "    total_cost = 0 \n",
    "    for i in range(total_batch):\n",
    "        batch_xs,batch_ys = Xtr[i*batch_size: (i+1)*batch_size],Ytr_onehot[i*batch_size: (i+1)*batch_size]\n",
    "        batch_xs = batch_xs.reshape(-1,int(image_x),int(image_y),int(image_z))\n",
    "            \n",
    "        _,curr_loss = sess.run([optimizer,cost],   \n",
    "                              feed_dict ={L0:batch_xs,Y:batch_ys,dropout_prob:0.7})\n",
    "        total_cost += curr_loss\n",
    "    \n",
    "    avg_cost = total_cost/total_batch\n",
    "    print('EPOCH : ' , '%04d' % (epoch),\n",
    "         'Avg.cost = ', '{:,.3f}'.format(avg_cost))\n",
    "  \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    accu('EPOCH: '+str(epoch)+' Avg.Cost: '+str(avg_cost))\n",
    "    if best_acc > accuracy:\n",
    "        off_switch += 1\n",
    "        if off_switch == 19: \n",
    "            email_sending.email2me(input_x +'Learning Finished with '+str(best_acc),'Last EPOCH: '+str(epoch)+' Avg.Cost: '+str(total_cost/total_batch)+'\\n'+structure,'/home/snu/Downloads/blank2.png') \n",
    "            email_sending.email2u(input_x +'Learning Finished with '+str(best_acc),'Last EPOCH: '+str(epoch)+' Avg.Cost: '+str(total_cost/total_batch)+'\\n'+structure,'/home/snu/Downloads/blank2.png')\n",
    "            break\n",
    "    elif best_acc <= accuracy: off_switch = 0 \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "\n",
    "models = []\n",
    "num_models = 10\n",
    "for m in range(num_models):\n",
    "    models.append(Model(sess, \"model\" + str(m)))\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "print('Learning Started!')\n",
    "\n",
    "# train my model\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost_list = np.zeros(len(models))\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        # train each model\n",
    "        for m_idx, m in enumerate(models):\n",
    "            c, _ = m.train(batch_xs, batch_ys)\n",
    "            avg_cost_list[m_idx] += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', avg_cost_list)\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "test_size = len(mnist.test.labels)\n",
    "predictions = np.zeros([test_size, 10])\n",
    "for m_idx, m in enumerate(models):\n",
    "    print(m_idx, 'Accuracy:', m.get_accuracy(\n",
    "        mnist.test.images, mnist.test.labels))\n",
    "    p = m.predict(mnist.test.images)\n",
    "    predictions += p\n",
    "\n",
    "ensemble_correct_prediction = tf.equal(\n",
    "    tf.argmax(predictions, 1), tf.argmax(mnist.test.labels, 1))\n",
    "ensemble_accuracy = tf.reduce_mean(\n",
    "    tf.cast(ensemble_correct_prediction, tf.float32))\n",
    "print('Ensemble accuracy:', sess.run(ensemble_accuracy))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
