{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import pickle, random, copy, platform, os, time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import email_sending\n",
    "import tflearn\n",
    "import tflearn.activations as activations\n",
    "from PIL import Image, ImageDraw\n",
    "from __future__ import division, print_function, absolute_import\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected, flatten, reshape\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d, avg_pool_2d,avg_pool_2d, highway_conv_2d,global_avg_pool\n",
    "from tflearn.layers.normalization import local_response_normalization, batch_normalization\n",
    "from tflearn.layers.merge_ops import merge\n",
    "from tflearn.layers.estimator import regression\n",
    "from tflearn.activations import relu\n",
    "from tflearn.data_utils import shuffle, to_categorical\n",
    "from tflearn.utils import repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    with open('resnet_data', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        Xtr = data[0]\n",
    "        Xtr = np.reshape(Xtr, (-1,75,75,2))\n",
    "        Ytr = data[1]\n",
    "        Xte =data[2]\n",
    "        Xte = np.reshape(Xte, (-1,75,75,2))\n",
    "        rf =data[3]\n",
    "    return Xtr, Ytr, Xte, rf\n",
    "\n",
    "# expresses the label data in one-hot encoding.\n",
    "def onehot_encoding (Y, y_class):\n",
    "    Y_onehot = np.zeros((Y.size, int(y_class)))\n",
    "    for i in range(Y.size):\n",
    "        Y_onehot[i][Y[i]] = 1\n",
    "    return Y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convnet(x, classes):\n",
    "    network = conv_2d(x, 32, 5, activation='elu', regularizer=\"L2\")\n",
    "    network = max_pool_2d(network, 2)\n",
    "    network = batch_normalization(network) #try with batch norm\n",
    "    network = conv_2d(network, 64, 5, activation='elu', regularizer=\"L2\")\n",
    "    network = max_pool_2d(network, 2)\n",
    "    network = batch_normalization(network)\n",
    "    network = conv_2d(network, 128, 5, activation='elu', regularizer=\"L2\")\n",
    "    network = batch_normalization(network)\n",
    "    network = fully_connected(network, 512, activation='elu')\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, 2048, activation='elu')\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, classes, activation='softmax')\n",
    "    return network\n",
    "\n",
    "def resnet(x, classes):\n",
    "    # Building Residual Network\n",
    "    net = tflearn.conv_2d(x, 64, 3, activation='elu', bias=False)\n",
    "    # Residual blocks\n",
    "    net = tflearn.residual_bottleneck(net, 3, 16, 64)\n",
    "    net = tflearn.residual_bottleneck(net, 1, 32, 128, downsample=True)\n",
    "    net = tflearn.residual_bottleneck(net, 2, 32, 128)\n",
    "    net = tflearn.residual_bottleneck(net, 1, 64, 256, downsample=True)\n",
    "    net = tflearn.residual_bottleneck(net, 2, 64, 256)\n",
    "    net = tflearn.batch_normalization(net)\n",
    "    net = tflearn.activation(net, 'elu')\n",
    "    net = tflearn.global_avg_pool(net)\n",
    "    # Regression\n",
    "    net = tflearn.fully_connected(net, classes, activation='softmax')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnet32(x, classes, n = 5): #classes =2\n",
    "    net = tflearn.conv_2d(x, 16, 3, regularizer='L2', weight_decay=0.0001)\n",
    "    net = tflearn.residual_block(net, n, 16)\n",
    "    net = tflearn.residual_block(net, 1, 32, downsample=True)\n",
    "    net = tflearn.residual_block(net, n - 1, 32)\n",
    "    net = tflearn.residual_block(net, 1, 64, downsample=True)\n",
    "    net = tflearn.residual_block(net, n - 1, 64)\n",
    "    net = tflearn.batch_normalization(net)\n",
    "    net = tflearn.activation(net, 'relu')\n",
    "    net = tflearn.global_avg_pool(net)\n",
    "    net = tflearn.fully_connected(net, classes, activation='softmax')\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def resnext(x, classes, n =5):\n",
    "    net = tflearn.conv_2d(x, 16, 3, regularizer='L2', weight_decay=0.0001)\n",
    "    net = tflearn.resnext_block(net, n, 16, 32)\n",
    "    net = tflearn.resnext_block(net, 1, 32, 32, downsample=True)\n",
    "    net = tflearn.resnext_block(net, n-1, 32, 32)\n",
    "    net = tflearn.resnext_block(net, 1, 64, 32, downsample=True)\n",
    "    net = tflearn.resnext_block(net, n-1, 64, 32)\n",
    "    net = tflearn.batch_normalization(net)\n",
    "    net = tflearn.activation(net, 'relu')\n",
    "    net = tflearn.global_avg_pool(net)\n",
    "    net = tflearn.fully_connected(net, classes, activation='softmax')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vgg(x, classes):    \n",
    "    network = conv_2d(x, 64, 3, activation='relu')\n",
    "    network = conv_2d(network, 64, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "    network = conv_2d(network, 128, 3, activation='relu')\n",
    "    network = conv_2d(network, 128, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "    network = conv_2d(network, 256, 3, activation='relu')\n",
    "    network = conv_2d(network, 256, 3, activation='relu')\n",
    "    network = conv_2d(network, 256, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "    network = conv_2d(network, 512, 3, activation='relu')\n",
    "    network = conv_2d(network, 512, 3, activation='relu')\n",
    "    network = conv_2d(network, 512, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "    network = conv_2d(network, 512, 3, activation='relu')\n",
    "    network = conv_2d(network, 512, 3, activation='relu')\n",
    "    network = conv_2d(network, 512, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 2, strides=2)\n",
    "\n",
    "    network = fully_connected(network, 4096, activation='relu')\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, 4096, activation='relu')\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, classes, activation='softmax')\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alexnet(x, classes):  \n",
    "    network = conv_2d(x, 96, 11, strides=4, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = conv_2d(network, 256, 5, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = conv_2d(network, 384, 3, activation='relu')\n",
    "    network = conv_2d(network, 384, 3, activation='relu')\n",
    "    network = conv_2d(network, 256, 3, activation='relu')\n",
    "    network = max_pool_2d(network, 3, strides=2)\n",
    "    network = local_response_normalization(network)\n",
    "    network = fully_connected(network, 4096, activation='tanh')\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, 4096, activation='tanh')\n",
    "    network = dropout(network, 0.5)\n",
    "    network = fully_connected(network, 2, activation='softmax')\n",
    "    \n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_high(x, classes):\n",
    "    for i in range(3):\n",
    "        for j in [3, 2, 1]: \n",
    "            network = highway_conv_2d(network, 16, j, activation='elu')\n",
    "        network = max_pool_2d(network, 2)\n",
    "        network = batch_normalization(network)\n",
    "\n",
    "    network = fully_connected(network, 128, activation='elu')\n",
    "    network = fully_connected(network, 256, activation='elu')\n",
    "    network = fully_connected(network, 2, activation='softmax')\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def densenet(x, classes):   \n",
    "    # Building Residual Network\n",
    "    net = tflearn.conv_2d(x, 16, 3, regularizer='L2', weight_decay=0.0001)\n",
    "    net = tflearn.densenet_block(net, nb_layers, k)\n",
    "    net = tflearn.densenet_block(net, nb_layers, k)\n",
    "    net = tflearn.densenet_block(net, nb_layers, k)\n",
    "    net = tflearn.global_avg_pool(net)\n",
    "    net = tflearn.fully_connected(net, 2, activation='softmax')\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def block35(net, scale=1.0, activation=\"relu\"):\n",
    "    tower_conv = relu(batch_normalization(conv_2d(net, 32, 1, bias=False, activation=None, name='Conv2d_1x1')))\n",
    "    tower_conv1_0 = relu(batch_normalization(conv_2d(net, 32, 1, bias=False, activation=None,name='Conv2d_0a_1x1')))\n",
    "    tower_conv1_1 = relu(batch_normalization(conv_2d(tower_conv1_0, 32, 3, bias=False, activation=None,name='Conv2d_0b_3x3')))\n",
    "    tower_conv2_0 = relu(batch_normalization(conv_2d(net, 32, 1, bias=False, activation=None, name='Conv2d_0a_1x1')))\n",
    "    tower_conv2_1 = relu(batch_normalization(conv_2d(tower_conv2_0, 48,3, bias=False, activation=None, name='Conv2d_0b_3x3')))\n",
    "    tower_conv2_2 = relu(batch_normalization(conv_2d(tower_conv2_1, 64,3, bias=False, activation=None, name='Conv2d_0c_3x3')))\n",
    "    tower_mixed = merge([tower_conv, tower_conv1_1, tower_conv2_2], mode='concat', axis=3)\n",
    "    tower_out = relu(batch_normalization(conv_2d(tower_mixed, net.get_shape()[3], 1, bias=False, activation=None, name='Conv2d_1x1')))\n",
    "    net += scale * tower_out\n",
    "    if activation:\n",
    "        if isinstance(activation, str):\n",
    "            net = activations.get(activation)(net)\n",
    "        elif hasattr(activation, '__call__'):\n",
    "            net = activation(net)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid Activation.\")\n",
    "    return net\n",
    "\n",
    "def block17(net, scale=1.0, activation=\"relu\"):\n",
    "    tower_conv = relu(batch_normalization(conv_2d(net, 192, 1, bias=False, activation=None, name='Conv2d_1x1')))\n",
    "    tower_conv_1_0 = relu(batch_normalization(conv_2d(net, 128, 1, bias=False, activation=None, name='Conv2d_0a_1x1')))\n",
    "    tower_conv_1_1 = relu(batch_normalization(conv_2d(tower_conv_1_0, 160,[1,7], bias=False, activation=None,name='Conv2d_0b_1x7')))\n",
    "    tower_conv_1_2 = relu(batch_normalization(conv_2d(tower_conv_1_1, 192, [7,1], bias=False, activation=None,name='Conv2d_0c_7x1')))\n",
    "    tower_mixed = merge([tower_conv,tower_conv_1_2], mode='concat', axis=3)\n",
    "    tower_out = relu(batch_normalization(conv_2d(tower_mixed, net.get_shape()[3], 1, bias=False, activation=None, name='Conv2d_1x1')))\n",
    "    net += scale * tower_out\n",
    "    if activation:\n",
    "        if isinstance(activation, str):\n",
    "            net = activations.get(activation)(net)\n",
    "        elif hasattr(activation, '__call__'):\n",
    "            net = activation(net)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid Activation.\")\n",
    "    return net\n",
    "\n",
    "\n",
    "def block8(net, scale=1.0, activation=\"relu\"):\n",
    "    tower_conv = relu(batch_normalization(conv_2d(net, 192, 1, bias=False, activation=None, name='Conv2d_1x1')))\n",
    "    tower_conv1_0 = relu(batch_normalization(conv_2d(net, 192, 1, bias=False, activation=None, name='Conv2d_0a_1x1')))\n",
    "    tower_conv1_1 = relu(batch_normalization(conv_2d(tower_conv1_0, 224, [1,3], bias=False, activation=None, name='Conv2d_0b_1x3')))\n",
    "    tower_conv1_2 = relu(batch_normalization(conv_2d(tower_conv1_1, 256, [3,1], bias=False, name='Conv2d_0c_3x1')))\n",
    "    tower_mixed = merge([tower_conv,tower_conv1_2], mode='concat', axis=3)\n",
    "    tower_out = relu(batch_normalization(conv_2d(tower_mixed, net.get_shape()[3], 1, bias=False, activation=None, name='Conv2d_1x1')))\n",
    "    net += scale * tower_out\n",
    "    if activation:\n",
    "        if isinstance(activation, str):\n",
    "            net = activations.get(activation)(net)\n",
    "        elif hasattr(activation, '__call__'):\n",
    "            net = activation(net)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid Activation.\")\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inception_resnet_v2(x, classes):\n",
    "    dropout_keep_prob = 0.8\n",
    "\n",
    "    conv1a_3_3 = relu(batch_normalization(conv_2d(x, 32, 3, strides=2, bias=False, padding='VALID',activation=None,name='Conv2d_1a_3x3')))\n",
    "    conv2a_3_3 = relu(batch_normalization(conv_2d(conv1a_3_3, 32, 3, bias=False, padding='VALID',activation=None, name='Conv2d_2a_3x3')))\n",
    "    conv2b_3_3 = relu(batch_normalization(conv_2d(conv2a_3_3, 64, 3, bias=False, activation=None, name='Conv2d_2b_3x3')))\n",
    "    maxpool3a_3_3 = max_pool_2d(conv2b_3_3, 3, strides=2, padding='VALID', name='MaxPool_3a_3x3')\n",
    "    conv3b_1_1 = relu(batch_normalization(conv_2d(maxpool3a_3_3, 80, 1, bias=False, padding='VALID',activation=None, name='Conv2d_3b_1x1')))\n",
    "    conv4a_3_3 = relu(batch_normalization(conv_2d(conv3b_1_1, 192, 3, bias=False, padding='VALID',activation=None, name='Conv2d_4a_3x3')))\n",
    "    maxpool5a_3_3 = max_pool_2d(conv4a_3_3, 3, strides=2, padding='VALID', name='MaxPool_5a_3x3')\n",
    "\n",
    "    tower_conv = relu(batch_normalization(conv_2d(maxpool5a_3_3, 96, 1, bias=False, activation=None, name='Conv2d_5b_b0_1x1')))\n",
    "\n",
    "    tower_conv1_0 = relu(batch_normalization(conv_2d(maxpool5a_3_3, 48, 1, bias=False, activation=None, name='Conv2d_5b_b1_0a_1x1')))\n",
    "    tower_conv1_1 = relu(batch_normalization(conv_2d(tower_conv1_0, 64, 5, bias=False, activation=None, name='Conv2d_5b_b1_0b_5x5')))\n",
    "\n",
    "    tower_conv2_0 = relu(batch_normalization(conv_2d(maxpool5a_3_3, 64, 1, bias=False, activation=None, name='Conv2d_5b_b2_0a_1x1')))\n",
    "    tower_conv2_1 = relu(batch_normalization(conv_2d(tower_conv2_0, 96, 3, bias=False, activation=None, name='Conv2d_5b_b2_0b_3x3')))\n",
    "    tower_conv2_2 = relu(batch_normalization(conv_2d(tower_conv2_1, 96, 3, bias=False, activation=None,name='Conv2d_5b_b2_0c_3x3')))\n",
    "\n",
    "    tower_pool3_0 = avg_pool_2d(maxpool5a_3_3, 3, strides=1, padding='same', name='AvgPool_5b_b3_0a_3x3')\n",
    "    tower_conv3_1 = relu(batch_normalization(conv_2d(tower_pool3_0, 64, 1, bias=False, activation=None,name='Conv2d_5b_b3_0b_1x1')))\n",
    "\n",
    "    tower_5b_out = merge([tower_conv, tower_conv1_1, tower_conv2_2, tower_conv3_1], mode='concat', axis=3)\n",
    "\n",
    "    net = repeat(tower_5b_out, 10, block35, scale=0.17)\n",
    "\n",
    "    tower_conv = relu(batch_normalization(conv_2d(net, 384, 3, bias=False, strides=2,activation=None, padding='VALID', name='Conv2d_6a_b0_0a_3x3')))\n",
    "    tower_conv1_0 = relu(batch_normalization(conv_2d(net, 256, 1, bias=False, activation=None, name='Conv2d_6a_b1_0a_1x1')))\n",
    "    tower_conv1_1 = relu(batch_normalization(conv_2d(tower_conv1_0, 256, 3, bias=False, activation=None, name='Conv2d_6a_b1_0b_3x3')))\n",
    "    tower_conv1_2 = relu(batch_normalization(conv_2d(tower_conv1_1, 384, 3, bias=False, strides=2, padding='VALID', activation=None,name='Conv2d_6a_b1_0c_3x3')))\n",
    "    tower_pool = max_pool_2d(net, 3, strides=2, padding='VALID',name='MaxPool_1a_3x3')\n",
    "    net = merge([tower_conv, tower_conv1_2, tower_pool], mode='concat', axis=3)\n",
    "    net = repeat(net, 20, block17, scale=0.1)\n",
    "\n",
    "    tower_conv = relu(batch_normalization(conv_2d(net, 256, 1, bias=False, activation=None, name='Conv2d_0a_1x1')))\n",
    "    tower_conv0_1 = relu(batch_normalization(conv_2d(tower_conv, 384, 3, bias=False, strides=2, padding='VALID', activation=None,name='Conv2d_0a_1x1')))\n",
    "\n",
    "    tower_conv1 = relu(batch_normalization(conv_2d(net, 256, 1, bias=False, padding='VALID', activation=None,name='Conv2d_0a_1x1')))\n",
    "    tower_conv1_1 = relu(batch_normalization(conv_2d(tower_conv1,288,3, bias=False, strides=2, padding='VALID',activation=None, name='COnv2d_1a_3x3')))\n",
    "\n",
    "    tower_conv2 = relu(batch_normalization(conv_2d(net, 256,1, bias=False, activation=None,name='Conv2d_0a_1x1')))\n",
    "    tower_conv2_1 = relu(batch_normalization(conv_2d(tower_conv2, 288,3, bias=False, name='Conv2d_0b_3x3',activation=None)))\n",
    "    tower_conv2_2 = relu(batch_normalization(conv_2d(tower_conv2_1, 320, 3, bias=False, strides=2, padding='VALID',activation=None, name='Conv2d_1a_3x3')))\n",
    "\n",
    "    tower_pool = max_pool_2d(net, 3, strides=2, padding='VALID', name='MaxPool_1a_3x3')\n",
    "    net = merge([tower_conv0_1, tower_conv1_1,tower_conv2_2, tower_pool], mode='concat', axis=3)\n",
    "\n",
    "    net = repeat(net, 9, block8, scale=0.2)\n",
    "    net = block8(net, activation=None)\n",
    "\n",
    "    net = relu(batch_normalization(conv_2d(net, 1536, 1, bias=False, activation=None, name='Conv2d_7b_1x1')))\n",
    "    net = avg_pool_2d(net, net.get_shape().as_list()[1:3],strides=2, padding='VALID', name='AvgPool_1a_8x8')\n",
    "    net = flatten(net)\n",
    "    net = dropout(net, dropout_keep_prob)\n",
    "    loss = fully_connected(net, classes,activation='softmax')\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def googlenet(x, classes):\n",
    "    conv1_7_7 = conv_2d(x, 64, 7, strides=2, activation='relu', name='conv1_7_7_s2')\n",
    "    pool1_3_3 = max_pool_2d(conv1_7_7, 3, strides=2)\n",
    "    pool1_3_3 = local_response_normalization(pool1_3_3)\n",
    "    conv2_3_3_reduce = conv_2d(pool1_3_3, 64, 1, activation='relu', name='conv2_3_3_reduce')\n",
    "    conv2_3_3 = conv_2d(conv2_3_3_reduce, 192, 3, activation='relu', name='conv2_3_3')\n",
    "    conv2_3_3 = local_response_normalization(conv2_3_3)\n",
    "    pool2_3_3 = max_pool_2d(conv2_3_3, kernel_size=3, strides=2, name='pool2_3_3_s2')\n",
    "\n",
    "    # 3a\n",
    "    inception_3a_1_1 = conv_2d(pool2_3_3, 64, 1, activation='relu', name='inception_3a_1_1')\n",
    "    inception_3a_3_3_reduce = conv_2d(pool2_3_3, 96, 1, activation='relu', name='inception_3a_3_3_reduce')\n",
    "    inception_3a_3_3 = conv_2d(inception_3a_3_3_reduce, 128, filter_size=3,  activation='relu', name='inception_3a_3_3')\n",
    "    inception_3a_5_5_reduce = conv_2d(pool2_3_3, 16, filter_size=1, activation='relu', name='inception_3a_5_5_reduce')\n",
    "    inception_3a_5_5 = conv_2d(inception_3a_5_5_reduce, 32, filter_size=5, activation='relu', name='inception_3a_5_5')\n",
    "    inception_3a_pool = max_pool_2d(pool2_3_3, kernel_size=3, strides=1, name='inception_3a_pool')\n",
    "    inception_3a_pool_1_1 = conv_2d(inception_3a_pool, 32, filter_size=1, activation='relu', name='inception_3a_pool_1_1')\n",
    "    inception_3a_output = merge([inception_3a_1_1, inception_3a_3_3, inception_3a_5_5, inception_3a_pool_1_1], mode='concat', axis=3)\n",
    "\n",
    "    # 3b\n",
    "    inception_3b_1_1 = conv_2d(inception_3a_output, 128, filter_size=1, activation='relu', name='inception_3b_1_1')\n",
    "    inception_3b_3_3_reduce = conv_2d(inception_3a_output, 128, filter_size=1, activation='relu', name='inception_3b_3_3_reduce')\n",
    "    inception_3b_3_3 = conv_2d(inception_3b_3_3_reduce, 192, filter_size=3, activation='relu', name='inception_3b_3_3')\n",
    "    inception_3b_5_5_reduce = conv_2d(inception_3a_output, 32, filter_size=1, activation='relu', name='inception_3b_5_5_reduce')\n",
    "    inception_3b_5_5 = conv_2d(inception_3b_5_5_reduce, 96, filter_size=5,  name='inception_3b_5_5')\n",
    "    inception_3b_pool = max_pool_2d(inception_3a_output, kernel_size=3, strides=1,  name='inception_3b_pool')\n",
    "    inception_3b_pool_1_1 = conv_2d(inception_3b_pool, 64, filter_size=1, activation='relu', name='inception_3b_pool_1_1')\n",
    "    inception_3b_output = merge([inception_3b_1_1, inception_3b_3_3, inception_3b_5_5, inception_3b_pool_1_1], mode='concat', axis=3, name='inception_3b_output')\n",
    "    pool3_3_3 = max_pool_2d(inception_3b_output, kernel_size=3, strides=2, name='pool3_3_3')\n",
    "\n",
    "    # 4a\n",
    "    inception_4a_1_1 = conv_2d(pool3_3_3, 192, filter_size=1, activation='relu', name='inception_4a_1_1')\n",
    "    inception_4a_3_3_reduce = conv_2d(pool3_3_3, 96, filter_size=1, activation='relu', name='inception_4a_3_3_reduce')\n",
    "    inception_4a_3_3 = conv_2d(inception_4a_3_3_reduce, 208, filter_size=3,  activation='relu', name='inception_4a_3_3')\n",
    "    inception_4a_5_5_reduce = conv_2d(pool3_3_3, 16, filter_size=1, activation='relu', name='inception_4a_5_5_reduce')\n",
    "    inception_4a_5_5 = conv_2d(inception_4a_5_5_reduce, 48, filter_size=5,  activation='relu', name='inception_4a_5_5')\n",
    "    inception_4a_pool = max_pool_2d(pool3_3_3, kernel_size=3, strides=1,  name='inception_4a_pool')\n",
    "    inception_4a_pool_1_1 = conv_2d(inception_4a_pool, 64, filter_size=1, activation='relu', name='inception_4a_pool_1_1')\n",
    "    inception_4a_output = merge([inception_4a_1_1, inception_4a_3_3, inception_4a_5_5, inception_4a_pool_1_1], mode='concat', axis=3, name='inception_4a_output')\n",
    "\n",
    "    # 4b\n",
    "    inception_4b_1_1 = conv_2d(inception_4a_output, 160, filter_size=1, activation='relu', name='inception_4a_1_1')\n",
    "    inception_4b_3_3_reduce = conv_2d(inception_4a_output, 112, filter_size=1, activation='relu', name='inception_4b_3_3_reduce')\n",
    "    inception_4b_3_3 = conv_2d(inception_4b_3_3_reduce, 224, filter_size=3, activation='relu', name='inception_4b_3_3')\n",
    "    inception_4b_5_5_reduce = conv_2d(inception_4a_output, 24, filter_size=1, activation='relu', name='inception_4b_5_5_reduce')\n",
    "    inception_4b_5_5 = conv_2d(inception_4b_5_5_reduce, 64, filter_size=5,  activation='relu', name='inception_4b_5_5')\n",
    "    inception_4b_pool = max_pool_2d(inception_4a_output, kernel_size=3, strides=1,  name='inception_4b_pool')\n",
    "    inception_4b_pool_1_1 = conv_2d(inception_4b_pool, 64, filter_size=1, activation='relu', name='inception_4b_pool_1_1')\n",
    "    inception_4b_output = merge([inception_4b_1_1, inception_4b_3_3, inception_4b_5_5, inception_4b_pool_1_1], mode='concat', axis=3, name='inception_4b_output')\n",
    "\n",
    "    # 4c\n",
    "    inception_4c_1_1 = conv_2d(inception_4b_output, 128, filter_size=1, activation='relu', name='inception_4c_1_1')\n",
    "    inception_4c_3_3_reduce = conv_2d(inception_4b_output, 128, filter_size=1, activation='relu', name='inception_4c_3_3_reduce')\n",
    "    inception_4c_3_3 = conv_2d(inception_4c_3_3_reduce, 256,  filter_size=3, activation='relu', name='inception_4c_3_3')\n",
    "    inception_4c_5_5_reduce = conv_2d(inception_4b_output, 24, filter_size=1, activation='relu', name='inception_4c_5_5_reduce')\n",
    "    inception_4c_5_5 = conv_2d(inception_4c_5_5_reduce, 64,  filter_size=5, activation='relu', name='inception_4c_5_5')\n",
    "    inception_4c_pool = max_pool_2d(inception_4b_output, kernel_size=3, strides=1)\n",
    "    inception_4c_pool_1_1 = conv_2d(inception_4c_pool, 64, filter_size=1, activation='relu', name='inception_4c_pool_1_1')\n",
    "    inception_4c_output = merge([inception_4c_1_1, inception_4c_3_3, inception_4c_5_5, inception_4c_pool_1_1], mode='concat', axis=3, name='inception_4c_output')\n",
    "\n",
    "    # 4d\n",
    "    inception_4d_1_1 = conv_2d(inception_4c_output, 112, filter_size=1, activation='relu', name='inception_4d_1_1')\n",
    "    inception_4d_3_3_reduce = conv_2d(inception_4c_output, 144, filter_size=1, activation='relu', name='inception_4d_3_3_reduce')\n",
    "    inception_4d_3_3 = conv_2d(inception_4d_3_3_reduce, 288, filter_size=3, activation='relu', name='inception_4d_3_3')\n",
    "    inception_4d_5_5_reduce = conv_2d(inception_4c_output, 32, filter_size=1, activation='relu', name='inception_4d_5_5_reduce')\n",
    "    inception_4d_5_5 = conv_2d(inception_4d_5_5_reduce, 64, filter_size=5,  activation='relu', name='inception_4d_5_5')\n",
    "    inception_4d_pool = max_pool_2d(inception_4c_output, kernel_size=3, strides=1,  name='inception_4d_pool')\n",
    "    inception_4d_pool_1_1 = conv_2d(inception_4d_pool, 64, filter_size=1, activation='relu', name='inception_4d_pool_1_1')\n",
    "    inception_4d_output = merge([inception_4d_1_1, inception_4d_3_3, inception_4d_5_5, inception_4d_pool_1_1], mode='concat', axis=3, name='inception_4d_output')\n",
    "\n",
    "    # 4e\n",
    "    inception_4e_1_1 = conv_2d(inception_4d_output, 256, filter_size=1, activation='relu', name='inception_4e_1_1')\n",
    "    inception_4e_3_3_reduce = conv_2d(inception_4d_output, 160, filter_size=1, activation='relu', name='inception_4e_3_3_reduce')\n",
    "    inception_4e_3_3 = conv_2d(inception_4e_3_3_reduce, 320, filter_size=3, activation='relu', name='inception_4e_3_3')\n",
    "    inception_4e_5_5_reduce = conv_2d(inception_4d_output, 32, filter_size=1, activation='relu', name='inception_4e_5_5_reduce')\n",
    "    inception_4e_5_5 = conv_2d(inception_4e_5_5_reduce, 128,  filter_size=5, activation='relu', name='inception_4e_5_5')\n",
    "    inception_4e_pool = max_pool_2d(inception_4d_output, kernel_size=3, strides=1,  name='inception_4e_pool')\n",
    "    inception_4e_pool_1_1 = conv_2d(inception_4e_pool, 128, filter_size=1, activation='relu', name='inception_4e_pool_1_1')\n",
    "    inception_4e_output = merge([inception_4e_1_1, inception_4e_3_3, inception_4e_5_5, inception_4e_pool_1_1], axis=3, mode='concat')\n",
    "    pool4_3_3 = max_pool_2d(inception_4e_output, kernel_size=3, strides=2, name='pool_3_3')\n",
    "\n",
    "    # 5a\n",
    "    inception_5a_1_1 = conv_2d(pool4_3_3, 256, filter_size=1, activation='relu', name='inception_5a_1_1')\n",
    "    inception_5a_3_3_reduce = conv_2d(pool4_3_3, 160, filter_size=1, activation='relu', name='inception_5a_3_3_reduce')\n",
    "    inception_5a_3_3 = conv_2d(inception_5a_3_3_reduce, 320, filter_size=3, activation='relu', name='inception_5a_3_3')\n",
    "    inception_5a_5_5_reduce = conv_2d(pool4_3_3, 32, filter_size=1, activation='relu', name='inception_5a_5_5_reduce')\n",
    "    inception_5a_5_5 = conv_2d(inception_5a_5_5_reduce, 128, filter_size=5,  activation='relu', name='inception_5a_5_5')\n",
    "    inception_5a_pool = max_pool_2d(pool4_3_3, kernel_size=3, strides=1,  name='inception_5a_pool')\n",
    "    inception_5a_pool_1_1 = conv_2d(inception_5a_pool, 128, filter_size=1, activation='relu', name='inception_5a_pool_1_1')\n",
    "    inception_5a_output = merge([inception_5a_1_1, inception_5a_3_3, inception_5a_5_5, inception_5a_pool_1_1], axis=3, mode='concat')\n",
    "\n",
    "    # 5b\n",
    "    inception_5b_1_1 = conv_2d(inception_5a_output, 384, filter_size=1, activation='relu', name='inception_5b_1_1')\n",
    "    inception_5b_3_3_reduce = conv_2d(inception_5a_output, 192, filter_size=1, activation='relu', name='inception_5b_3_3_reduce')\n",
    "    inception_5b_3_3 = conv_2d(inception_5b_3_3_reduce, 384,  filter_size=3, activation='relu', name='inception_5b_3_3')\n",
    "    inception_5b_5_5_reduce = conv_2d(inception_5a_output, 48, filter_size=1, activation='relu', name='inception_5b_5_5_reduce')\n",
    "    inception_5b_5_5 = conv_2d(inception_5b_5_5_reduce, 128, filter_size=5, activation='relu', name='inception_5b_5_5')\n",
    "    inception_5b_pool = max_pool_2d(inception_5a_output, kernel_size=3, strides=1,  name='inception_5b_pool')\n",
    "    inception_5b_pool_1_1 = conv_2d(inception_5b_pool, 128, filter_size=1, activation='relu', name='inception_5b_pool_1_1')\n",
    "    inception_5b_output = merge([inception_5b_1_1, inception_5b_3_3, inception_5b_5_5, inception_5b_pool_1_1], axis=3, mode='concat')\n",
    "    pool5_7_7 = avg_pool_2d(inception_5b_output, kernel_size=7, strides=1)\n",
    "    pool5_7_7 = dropout(pool5_7_7, 0.4)\n",
    "\n",
    "    # fc\n",
    "    net = fully_connected(pool5_7_7, classes, activation='softmax')\n",
    "    \n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_ensemble = 7\n",
    "ensemble = np.zeros((n_ensemble, 8424, 2))\n",
    "\n",
    "def predict(model, test_data, ref, mode, count):\n",
    "    #8424=8*81*13\n",
    "    batch_size =104\n",
    "    iteration = int(len(test_data)/batch_size)  #iter=81  \n",
    "    \n",
    "    with open(\"C:/Users/User/Desktop/kaggle/result_{0}.txt\".format(mode), \"w\") as f:\n",
    "        f.write(\"id,is_iceberg\\n\")\n",
    "        for i in range(iteration):\n",
    "            pred = model.predict(test_data[i*batch_size: (i+1)*batch_size])\n",
    "            ensemble[count][i*batch_size: (i+1)*batch_size] = pred\n",
    "            for j in range(batch_size):\n",
    "                data = \"%s,%f\\n\" % (ref[i*batch_size+j], pred[j][1])\n",
    "                f.write(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir = 'checkpoints/'\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "    \n",
    "def get_save_path(net_name):\n",
    "    return save_dir + str(net_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EarlyStoppingCallback(tflearn.callbacks.Callback):\n",
    "    def __init__(self, val_acc_thresh):\n",
    "        \"\"\" Note: We are free to define our init function however we please. \"\"\"\n",
    "        self.val_acc_thresh = val_acc_thresh\n",
    "    \n",
    "    def on_epoch_end(self, training_state):\n",
    "        \"\"\" \"\"\"\n",
    "        # Apparently this can happen.\n",
    "        if training_state.val_acc is None: return\n",
    "        if training_state.val_acc > self.val_acc_thresh:\n",
    "            raise StopIteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtr, Ytr, Xte, ref = read_data()\n",
    "\n",
    "Xtr, Ytr = tflearn.data_utils.shuffle(Xtr, Ytr)\n",
    "Ytr = onehot_encoding (Ytr, 2)\n",
    "\n",
    "Xtr, mean = tflearn.data_utils.featurewise_zero_center(Xtr)\n",
    "\n",
    "\n",
    "#data split\n",
    "X, Y = Xtr[:1200], Ytr[:1200]\n",
    "validX, validY =Xtr[1200:1500], Ytr[1200:1500]\n",
    "testX, testY = Xtr[1500:],Ytr[1500:]\n",
    "\n",
    "X= tflearn.data_utils.featurewise_zero_center(X, mean)\n",
    "testX = tflearn.data_utils.featurewise_zero_center(testX, mean)\n",
    "validX = tflearn.data_utils.featurewise_zero_center(validX, mean)\n",
    "\n",
    "#augmentation\n",
    "img_aug = tflearn.ImageAugmentation()\n",
    "img_aug.add_random_flip_leftright()\n",
    "img_aug.add_random_90degrees_rotation(rotations=[0, 1, 2, 3])\n",
    "img_aug.add_random_crop([75,75,2], padding=4)\n",
    "\n",
    "#input tensor\n",
    "Input = tflearn.input_data(shape=[None, 75, 75, 2], dtype='float', name ='input', data_augmentation=img_aug)\n",
    "early_stopping_cb = EarlyStoppingCallback(val_acc_thresh=0.95) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(mode, num_epochs = 20, batch_size=100, classes=2, n_ens = 0):\n",
    "    \n",
    "    if mode =='convnet':\n",
    "        network = tflearn.regression(convnet(Input,classes),optimizer='adam',loss='categorical_crossentropy', name ='target')\n",
    "        model = tflearn.DNN(network,tensorboard_verbose=3,tensorboard_dir='c:\\\\tflearn_logs\\\\')\n",
    "        model.fit({'input': X}, {'target': Y}, n_epoch=num_epochs, validation_set=({'input': validX}, {'target': validY}),\n",
    "                  show_metric=True, callbacks=early_stopping_cb,batch_size=batch_size, run_id='convnet')\n",
    "        predict(model, Xte, ref, mode, n_ens)\n",
    "        \n",
    "    elif mode =='resnet':\n",
    "        network = tflearn.regression(resnet(Input,classes),optimizer='adam',loss='categorical_crossentropy', name ='target')\n",
    "        model = tflearn.DNN(network,tensorboard_verbose=3,tensorboard_dir='c:\\\\tflearn_logs\\\\')\n",
    "        model.fit({'input': X}, {'target': Y}, n_epoch=num_epochs, validation_set=({'input': validX}, {'target': validY}),\n",
    "                  show_metric=True, callbacks=early_stopping_cb,batch_size=batch_size, run_id='resnet')\n",
    "        predict(model, Xte, ref, mode, n_ens)\n",
    "  \n",
    "    elif mode =='resnet32':\n",
    "        network = tflearn.regression(resnet32(Input,classes),optimizer='adam',loss='categorical_crossentropy', name ='target')\n",
    "        model = tflearn.DNN(network,tensorboard_verbose=3,tensorboard_dir='c:\\\\tflearn_logs\\\\')\n",
    "        model.fit({'input': X}, {'target': Y}, n_epoch=num_epochs, validation_set=({'input': validX}, {'target': validY}),\n",
    "                  show_metric=True, callbacks=early_stopping_cb,batch_size=batch_size, run_id='resnet32')\n",
    "        predict(model, Xte, ref, mode, n_ens)\n",
    "\n",
    "    elif mode =='inception_resnet_v2':        \n",
    "        network = tflearn.regression(inception_resnet_v2(Input,classes),\n",
    "                                     optimizer='adam',loss='categorical_crossentropy',name ='target')\n",
    "        model = tflearn.DNN(network,tensorboard_verbose=3,tensorboard_dir='c:\\\\tflearn_logs\\\\')\n",
    "        model.fit({'input': X}, {'target': Y}, n_epoch=num_epochs, show_metric=True, batch_size=batch_size,\n",
    "                  validation_set=({'input': validX}, {'target': validY}),callbacks=early_stopping_cb, run_id ='inception_resnet_v2')\n",
    "        predict(model, Xte, ref, mode, n_ens)\n",
    "\n",
    "    elif mode=='resnext':\n",
    "        network = tflearn.regression(resnext(Input,classes), optimizer='adam',loss='categorical_crossentropy', name ='target')\n",
    "        model = tflearn.DNN(network, tensorboard_verbose=3,tensorboard_dir='c:\\\\tflearn_logs\\\\')\n",
    "        model.fit({'input': X}, {'target': Y}, n_epoch=num_epochs, validation_set=({'input': validX}, {'target': validY}),\n",
    "                  show_metric=True, batch_size=batch_size, callbacks=early_stopping_cb,run_id='resnext')\n",
    "        predict(model, Xte, ref, mode, n_ens)\n",
    "        \n",
    "    elif mode=='googlenet':\n",
    "        network = regression(googlenet(Input,classes),  optimizer='adam',loss='categorical_crossentropy',name ='target')\n",
    "        model = tflearn.DNN(network, tensorboard_verbose=3, tensorboard_dir='c:\\\\tflearn_logs\\\\')\n",
    "        model.fit({'input': X}, {'target': Y}, n_epoch=num_epochs, validation_set=({'input': validX}, {'target': validY}),\n",
    "                  show_metric=True,  batch_size=batch_size, callbacks=early_stopping_cb, run_id='googlenet')\n",
    "        predict(model, Xte, ref, mode, n_ens)\n",
    "\n",
    "    elif mode=='vgg':\n",
    "        network = regression(vgg(Input,classes), optimizer='adam',loss='categorical_crossentropy', name ='target')\n",
    "        model = tflearn.DNN(network,tensorboard_verbose=3, tensorboard_dir='c:\\\\tflearn_logs\\\\')\n",
    "        model.fit({'input': X}, {'target': Y}, n_epoch=num_epochs, validation_set=({'input': validX}, {'target': validY}),\n",
    "                  show_metric=True,  batch_size=batch_size, callbacks=early_stopping_cb, run_id='vgg')\n",
    "        predict(model, Xte, ref, mode, n_ens)\n",
    "    \n",
    "    elif mode =='alexnet':\n",
    "        network = regression(alexnet(Input,classes), optimizer='adam',loss='categorical_crossentropy', name ='target')\n",
    "        model = tflearn.DNN(network,tensorboard_verbose=3, tensorboard_dir='c:\\\\tflearn_logs\\\\')\n",
    "        model.fit({'input': X}, {'target': Y}, n_epoch=num_epochs, validation_set=({'input': validX}, {'target': validY}),\n",
    "                  show_metric=True,  batch_size=batch_size, callbacks=early_stopping_cb, run_id='alexnet')\n",
    "        predict(model, Xte, ref, mode, n_ens)\n",
    "                  \n",
    "    elif mode =='conv_high':\n",
    "        network = regression(conv_high(Input,classes), optimizer='adam',loss='categorical_crossentropy', name ='target')\n",
    "        model = tflearn.DNN(network,tensorboard_verbose=3, tensorboard_dir='c:\\\\tflearn_logs\\\\')\n",
    "        model.fit({'input': X}, {'target': Y}, n_epoch=num_epochs, validation_set=({'input': validX}, {'target': validY}),\n",
    "                  show_metric=True,  batch_size=batch_size, callbacks=early_stopping_cb, run_id='conv_high')\n",
    "        predict(model, Xte, ref, mode, n_ens)\n",
    "        \n",
    "    elif mode == 'densenet':\n",
    "        network = regression(densenet(Input,classes), optimizer='adam',loss='categorical_crossentropy', name ='target') \n",
    "        model = tflearn.DNN(network,tensorboard_verbose=3, tensorboard_dir='c:\\\\tflearn_logs\\\\')\n",
    "        model.fit({'input': X}, {'target': Y}, n_epoch=num_epochs, validation_set=({'input': validX}, {'target': validY}),\n",
    "                  show_metric=True,  batch_size=batch_size, callbacks=early_stopping_cb, run_id='densenet')\n",
    "        predict(model, Xte, ref, mode, n_ens)\n",
    "\n",
    "    else:\n",
    "        print(\"Please Select Mode in ['resnet32', 'inception_resnet_v2', 'resnext', 'googlenet','vgg', 'convnet', 'resnet'\\\n",
    "               'alexnet' 'conv_high', 'densenet']\")\n",
    "\n",
    "    model.save(get_save_path(mode))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'network' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-e2fbd9254f6d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'conv_high'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_ens\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-cf0ec5bbde2e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(mode, num_epochs, batch_size, classes, n_ens)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m\u001b[1;34m'conv_high'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mregression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv_high\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'adam'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'categorical_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'target'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtflearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDNN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtensorboard_verbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensorboard_dir\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c:\\\\tflearn_logs\\\\'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         model.fit({'input': X}, {'target': Y}, n_epoch=num_epochs, validation_set=({'input': validX}, {'target': validY}),\n",
      "\u001b[1;32m<ipython-input-8-338ab0ade846>\u001b[0m in \u001b[0;36mconv_high\u001b[1;34m(x, classes)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhighway_conv_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'elu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_pool_2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_normalization\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'network' referenced before assignment"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train('conv_high', num_epochs = 1, batch_size=100, classes=2, n_ens= 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train('resnet', num_epochs = 40, batch_size=100, classes=2, n_ens= 0)\n",
    "train('vgg', num_epochs = 40, batch_size=100, classes=2, n_ens= 1)\n",
    "train('googlenet', num_epochs = 40, batch_size=100, classes=2, n_ens= 2)\n",
    "train('alexnet', num_epochs = 40, batch_size=100, classes=2, n_ens= 3)\n",
    "train('densenet', num_epochs = 40, batch_size=100, classes=2, n_ens= 4)\n",
    "train('conv_high', num_epochs = 40, batch_size=100, classes=2, n_ens= 5)\n",
    "train('convnet', num_epochs = 40, batch_size=100, classes=2, n_ens= 6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
