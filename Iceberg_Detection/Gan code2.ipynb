{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from skimage.io import imsave\n",
    "import os\n",
    "import shutil\n",
    "import pickle, random, copy, platform\n",
    "import email_sending\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vessel_img():\n",
    "    with open('vessel', 'rb') as vessel:\n",
    "        data = pickle.load(vessel)\n",
    "        band1 = data[0]\n",
    "        band2 = data[1]\n",
    "\n",
    "    return band1, band2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#band1\n",
    "band1 = vessel_img()[0]\n",
    "band2 = vessel_img()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X1 = band1.reshape(-1, 5625)\n",
    "X2 = band2.reshape(-1, 5625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_height = 75\n",
    "img_width = 75\n",
    "img_size = img_height * img_width\n",
    "\n",
    "to_train = True\n",
    "to_restore = False\n",
    "output_path = \"output\"\n",
    "\n",
    "max_epoch = 500\n",
    "\n",
    "h1_size = 1024\n",
    "h2_size = 2048\n",
    "z_size = 512\n",
    "batch_size = 37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 제너레이터 (G)\n",
    "def build_generator(z_prior):\n",
    "    # Fully Connected Layer 1 (512 (latent-vector: z_size) -> 1024 (h1_size))\n",
    "    w1 = tf.Variable(tf.truncated_normal([z_size, h1_size], stddev=0.1), name=\"g_w1\", dtype=tf.float32)\n",
    "    b1 = tf.Variable(tf.zeros([h1_size]), name=\"g_b1\", dtype=tf.float32)\n",
    "    h1 = tf.nn.relu(tf.matmul(z_prior, w1) + b1)\n",
    "\n",
    "    # Fully Connected Layer 2 (1024(h1_size) -> 2048 (h2_size))\n",
    "    w2 = tf.Variable(tf.truncated_normal([h1_size, h2_size], stddev=0.1), name=\"g_w2\", dtype=tf.float32)\n",
    "    b2 = tf.Variable(tf.zeros([h2_size]), name=\"g_b2\", dtype=tf.float32)\n",
    "    h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)\n",
    "\n",
    "    # Fully Connected Layer 3 (2048 (h1_size) -> input_height * input_width (img_size))\n",
    "    w3 = tf.Variable(tf.truncated_normal([h2_size, img_size], stddev=0.1), name=\"g_w3\", dtype=tf.float32)\n",
    "    b3 = tf.Variable(tf.zeros([img_size]), name=\"g_b3\", dtype=tf.float32)\n",
    "    h3 = tf.matmul(h2, w3) + b3\n",
    "    # 마지막은 활성화함수 tanh 로\n",
    "    x_generate = tf.nn.tanh(h3)\n",
    "\n",
    "    # generator 변수 저장\n",
    "    g_params = [w1, b1, w2, b2, w3, b3]\n",
    "\n",
    "    return x_generate, g_params\n",
    "\n",
    "# 디스크리미네이터 (D)\n",
    "def build_discriminator(x_data, x_generated, keep_prob):\n",
    "    # 실제 이미지와 생성된 이미지를 합침\n",
    "    x_in = tf.concat([x_data, x_generated], 0) \n",
    "\n",
    "    # Fully Connected Layer 1 (input_height * input_width (img_size) -> 2048 (h2_size)) , dropout\n",
    "    w1 = tf.Variable(tf.truncated_normal([img_size, h2_size], stddev=0.1), name=\"d_w1\", dtype=tf.float32)\n",
    "    b1 = tf.Variable(tf.zeros([h2_size]), name=\"d_b1\", dtype=tf.float32)\n",
    "    h1 = tf.nn.dropout(tf.nn.relu(tf.matmul(x_in, w1) + b1), keep_prob)\n",
    "\n",
    "    # Fully Connected Layer 2 (2048 (h2_size) -> 1024 (h1_size)) , dropout\n",
    "    w2 = tf.Variable(tf.truncated_normal([h2_size, h1_size], stddev=0.1), name=\"d_w2\", dtype=tf.float32)\n",
    "    b2 = tf.Variable(tf.zeros([h1_size]), name=\"d_b2\", dtype=tf.float32)\n",
    "    h2 = tf.nn.dropout(tf.nn.relu(tf.matmul(h1, w2) + b2), keep_prob)\n",
    "\n",
    "    # Fully Connected Layer 3 (1024 (h1_size) -> 1)\n",
    "    w3 = tf.Variable(tf.truncated_normal([h1_size, 1], stddev=0.1), name=\"d_w3\", dtype=tf.float32)\n",
    "    b3 = tf.Variable(tf.zeros([1]), name=\"d_b3\", dtype=tf.float32)\n",
    "    h3 = tf.matmul(h2, w3) + b3\n",
    "\n",
    "    # batch_size 만큼 잘라 각각 y_data, y_generated 로\n",
    "    # ex)\n",
    "    #   이미지 1604개, 배치 사이즈 37, 이미지 사이즈 75 * 75 이라면\n",
    "    #   h3 shape : (38, 1)\n",
    "    #   y_data shape : (37, 1)\n",
    "    #   y_generated shape : (1, 1) \n",
    "    y_data = tf.nn.sigmoid(tf.slice(h3, [0, 0], [batch_size, -1], name=None))\n",
    "    y_generated = tf.nn.sigmoid(tf.slice(h3, [batch_size, 0], [-1, -1], name=None))\n",
    "\n",
    "    # discriminator 변수 저장\n",
    "    d_params = [w1, b1, w2, b2, w3, b3]\n",
    "\n",
    "    return y_data, y_generated, d_params\n",
    "\n",
    "# 결과 저장 (이미지)\n",
    "def show_result(batch_res, fname, grid_size=(8, 8), grid_pad=5):\n",
    "    batch_res = 0.5 * batch_res.reshape((batch_res.shape[0], img_height, img_width)) + 0.5\n",
    "    img_h, img_w = batch_res.shape[1], batch_res.shape[2]\n",
    "    grid_h = img_h * grid_size[0] + grid_pad * (grid_size[0] - 1)\n",
    "    grid_w = img_w * grid_size[1] + grid_pad * (grid_size[1] - 1)\n",
    "    img_grid = np.zeros((grid_h, grid_w), dtype=np.uint8)\n",
    "    for i, res in enumerate(batch_res):\n",
    "        if i >= grid_size[0] * grid_size[1]:\n",
    "            break\n",
    "        img = (res) * 255.\n",
    "        img = img.astype(np.uint8)\n",
    "        row = (i // grid_size[0]) * (img_h + grid_pad)\n",
    "        col = (i % grid_size[1]) * (img_w + grid_pad)\n",
    "        img_grid[row:row + img_h, col:col + img_w] = img\n",
    "    imsave(fname, img_grid)\n",
    "\n",
    "\n",
    "def train():\n",
    "    # mnist 로 학습할 경우\n",
    "    # mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    \n",
    "    # phd08 로 학습할 경우\n",
    "    #phd08 = np.load('phd08_data_1.npy')\n",
    "    #size = phd08.shape[0]\n",
    "    #phd08 = phd08.reshape((size,784))\n",
    "    \n",
    "    #vessel로 학습할 경우\n",
    "    size = len(band1)\n",
    "    X1 = band1.reshape(size, 5625)\n",
    "    \n",
    "    x_data = tf.placeholder(tf.float32, [batch_size, img_size], name=\"x_data\") # (batch_size, img_size)\n",
    "    z_prior = tf.placeholder(tf.float32, [batch_size, z_size], name=\"z_prior\") # (batch_size, z_size)\n",
    "    keep_prob = tf.placeholder(tf.float32, name=\"keep_prob\") # dropout 퍼센트\n",
    "    global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "\n",
    "    # x_generated : generator 가 생성한 이미지, g_params : generater 의 TF 변수들\n",
    "    x_generated, g_params = build_generator(z_prior)\n",
    "    # 실제이미지, generater 가 생성한 이미지, dropout keep_prob 를 넣고 discriminator(경찰) 이 감별\n",
    "    y_data, y_generated, d_params = build_discriminator(x_data, x_generated, keep_prob)\n",
    "\n",
    "    # loss 함수 ( D 와 G 를 따로 ) *\n",
    "    d_loss = - (tf.log(y_data) + tf.log(1 - y_generated))\n",
    "    g_loss = - tf.log(y_generated)\n",
    "\n",
    "    # optimizer : AdamOptimizer 사용 *\n",
    "    optimizer = tf.train.AdamOptimizer(0.00001)\n",
    "\n",
    "    # discriminator 와 generator 의 변수로 각각의 loss 함수를 최소화시키도록 학습\n",
    "    d_trainer = optimizer.minimize(d_loss, var_list=d_params)\n",
    "    g_trainer = optimizer.minimize(g_loss, var_list=g_params)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    sess = tf.Session()\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    if to_restore:\n",
    "        chkpt_fname = tf.train.latest_checkpoint(output_path)\n",
    "        saver.restore(sess, chkpt_fname)\n",
    "    else:\n",
    "        if os.path.exists(output_path):\n",
    "            shutil.rmtree(output_path)\n",
    "        os.mkdir(output_path)\n",
    "\n",
    "    z_sample_val = np.random.normal(0, 1, size=(batch_size, z_size)).astype(np.float32)\n",
    "\n",
    "    for i in range(sess.run(global_step), max_epoch):\n",
    "        for j in range(size // batch_size):\n",
    "            print(\"epoch:%s, iter:%s\" % (i, j))\n",
    "\n",
    "            # x_value, _ = mnist.train.next_batch(batch_size)\n",
    "            # x_value = 2 * x_value.astype(np.float32) - 1\n",
    "            # print(x_value[0])\n",
    "\n",
    "            batch_end = j * batch_size + batch_size\n",
    "            x_value = X1[ j * batch_size : batch_end ]\n",
    "            x_value = x_value / 255.\n",
    "            x_ue = 2 * x_value - 1\n",
    "\n",
    "            z_value = np.random.normal(0, 1, size=(batch_size, z_size)).astype(np.float32)\n",
    "            sess.run(d_trainer,\n",
    "                     feed_dict={x_data: x_value, z_prior: z_value, keep_prob: np.sum(0.7).astype(np.float32)})\n",
    "            if j % 1 == 0:\n",
    "                sess.run(g_trainer,\n",
    "                         feed_dict={x_data: x_value, z_prior: z_value, keep_prob: np.sum(0.7).astype(np.float32)})\n",
    "        x_gen_val = sess.run(x_generated, feed_dict={z_prior: z_sample_val})\n",
    "        show_result(x_gen_val, os.path.join(output_path, \"sample%s.jpg\" % i))\n",
    "        print(x_gen_val)\n",
    "        z_random_sample_val = np.random.normal(0, 1, size=(batch_size, z_size)).astype(np.float32)\n",
    "        x_gen_val = sess.run(x_generated, feed_dict={z_prior: z_random_sample_val})\n",
    "        show_result(x_gen_val, os.path.join(output_path, \"random_sample%s.jpg\" % i))\n",
    "        sess.run(tf.assign(global_step, i + 1))\n",
    "        saver.save(sess, os.path.join(output_path, \"model\"), global_step=global_step)\n",
    "\n",
    "# 학습 완료 후 테스트 (이미지로 저장)\n",
    "def test():\n",
    "    z_prior = tf.placeholder(tf.float32, [batch_size, z_size], name=\"z_prior\")\n",
    "    x_generated, _ = build_generator(z_prior)\n",
    "    chkpt_fname = tf.train.latest_checkpoint(output_path)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n",
    "    sess = tf.Session()\n",
    "    saver = tf.train.Saver()\n",
    "    sess.run(init)\n",
    "    saver.restore(sess, chkpt_fname)\n",
    "    z_test_value = np.random.normal(0, 1, size=(batch_size, z_size)).astype(np.float32)\n",
    "    x_gen_val = sess.run(x_generated, feed_dict={z_prior: z_test_value})\n",
    "    show_result(x_gen_val, os.path.join(output_path, \"test_result.jpg\"))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if to_train:\n",
    "        train()\n",
    "    else:\n",
    "        test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
