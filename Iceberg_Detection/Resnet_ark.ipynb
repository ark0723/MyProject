{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tflearn\n",
    "import numpy as np\n",
    "from data import DataHandler\n",
    "#from network_defs import *\n",
    "import time\n",
    "import os\n",
    "\n",
    "tf.python.control_flow_ops = tf\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def resnet1(x, classes, n = 5):\n",
    "    net = tflearn.conv_2d(x, 16, 3, regularizer='L2', weight_decay=0.0001)\n",
    "    net = tflearn.residual_block(net, n, 16)\n",
    "    net = tflearn.residual_block(net, 1, 32, downsample=True)\n",
    "    net = tflearn.residual_block(net, n - 1, 32)\n",
    "    net = tflearn.residual_block(net, 1, 64, downsample=True)\n",
    "    net = tflearn.residual_block(net, n - 1, 64)\n",
    "    net = tflearn.batch_normalization(net)\n",
    "    net = tflearn.activation(net, 'relu')\n",
    "    net = tflearn.global_avg_pool(net)\n",
    "    net = tflearn.fully_connected(net, classes, activation='softmax')\n",
    "\n",
    "    return net\n",
    "\n",
    "def train_nn_tflearn(data_handler,num_epochs=50):\n",
    "\n",
    "\t#gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "\t#tflearn.init_graph(gpu_memory_fraction=0.5)\n",
    "\n",
    "\tbatch_size = data_handler.mini_batch_size\n",
    "\tclasses = data_handler.num_labels\n",
    "\n",
    "\timg_prep = tflearn.ImagePreprocessing()\n",
    "\timg_prep.add_featurewise_zero_center()\n",
    "\timg_prep.add_featurewise_stdnorm()\n",
    "\n",
    "\timg_aug = tflearn.ImageAugmentation()\n",
    "\timg_aug.add_random_flip_leftright()\n",
    "\timg_aug.add_random_rotation(max_angle=25)\n",
    "\t#img_aug.add_random_crop([32,32], padding=4)\n",
    "\n",
    "\tx = tflearn.input_data(shape=[None, 128, 128, 1], dtype='float', data_preprocessing=img_prep,\n",
    "\t\t\t\t\t\t   data_augmentation=img_aug)\n",
    "\t# x = tf.placeholder('float', [None, 32, 32, 3])\n",
    "\t#y = tf.placeholder('float', [None, 10])\n",
    "\n",
    "\t# test_data, test_labels = data_handler.get_test_data()\n",
    "\t# test_data = test_data.reshape([-1,32,32,3])\n",
    "\n",
    "\tntrain = data_handler.train_size\n",
    "\tntest = data_handler.meta['num_cases_per_batch']\n",
    "\n",
    "\t# from tflearn.datasets import cifar10\n",
    "\t# (X, Y), (X_test, Y_test) = cifar10.load_data(dirname=\"/home/hamza/meh/bk_fedora24/Documents/tflearn_example/cifar-10-batches-py\")\n",
    "\t# X, Y = tflearn.data_utils.shuffle(X, Y)\n",
    "\t# Y = tflearn.data_utils.to_categorical(Y, 10)\n",
    "\t# Y_test = tflearn.data_utils.to_categorical(Y_test, 10)\n",
    "\n",
    "\tX, Y = data_handler.get_all_train_data()\n",
    "\n",
    "\tX, Y = tflearn.data_utils.shuffle(X, Y)\n",
    "\n",
    "\t#X = np.dstack((X[:, :128*128], X[:, 128*128:]))\n",
    "\tX = X[:,:128*128]\n",
    "\n",
    "\t#X = X/255.0\n",
    "\n",
    "\t#X = X.reshape([-1,128,128,2])\n",
    "\tX = X.reshape([-1,128,128,1])\n",
    "\t\n",
    "\tY = tflearn.data_utils.to_categorical(Y,classes)\n",
    "\n",
    "\tX_test, Y_test = data_handler.get_test_data()\n",
    "\n",
    "\t#X_test = np.dstack((X_test[:, :128*128], X_test[:, 128*128:]))\n",
    "\tX_test = X_test[:,:128*128]\n",
    "\t#X_test = X_test/255.0\n",
    "\n",
    "\t#X_test = X_test.reshape([-1,128,128,2])\n",
    "\tX_test = X_test.reshape([-1,128,128,1])\n",
    "\t#network = tflearn.regression(net3(x),optimizer='adam',loss='categorical_crossentropy',learning_rate=0.001)\n",
    "\t#mom = tflearn.Momentum(0.1, lr_decay=0.1, decay_step=32000, staircase=True)\n",
    "\t#network = tflearn.regression(resnet1(x),optimizer='sgd',loss='categorical_crossentropy')\n",
    "\tnetwork = tflearn.regression(resnet1(x,classes),optimizer='adam',loss='categorical_crossentropy')\n",
    "\tprint np.shape(X)\n",
    "\tprint np.shape(Y)\n",
    "\tprint network\n",
    "\n",
    "\tif not os.path.exists('/tmp/tflearn/checkpoints'):\n",
    "\t\tos.makedirs('/tmp/tflearn/checkpoints')\n",
    "\n",
    "\tmodel = tflearn.DNN(network,tensorboard_verbose=3,checkpoint_path='/tmp/tflearn/checkpoints/',best_checkpoint_path='best/',best_val_accuracy=0.90)\n",
    "\tmodel.fit(X, Y, n_epoch=num_epochs, shuffle=True, validation_set=(X_test, Y_test),\n",
    "\t\t\t  show_metric=True, batch_size=data_handler.mini_batch_size, run_id='mstar_cnn')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\timport sys\n",
    "\n",
    "\tbl = sys.argv[1]\n",
    "\tnb = int(sys.argv[2])\n",
    "\tmbs = int(sys.argv[3])\n",
    "\tnep = int(sys.argv[4])\n",
    "\n",
    "\thandler = DataHandler(bl,nb,mbs)\n",
    "\t#train_nn(0,handler)\n",
    "\ttrain_nn_tflearn(handler,nep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curses is not supported on this machine (please install/reinstall curses for an optimal experience)\n"
     ]
    }
   ],
   "source": [
    "import pickle, random, copy, platform, os, time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import email_sending\n",
    "from PIL import Image, ImageDraw\n",
    "import tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    with open('resnet_data', 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        Xtr = data[0]\n",
    "        Ytr = data[1]\n",
    "    return Xtr, Ytr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1604, 5625, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.00005\n",
    "training_epochs = 10\n",
    "batch_size = 100\n",
    "n_class=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# expresses the label data in one-hot encoding.\n",
    "def onehot_encoding (label):\n",
    "    onehot_y = np.zeros((label.size, int(n_class)))\n",
    "    for i in range(label.size):\n",
    "        onehot_y[i][label[i]] = 1\n",
    "    return onehot_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 0.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.],\n",
       "       [ 1.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot_y = onehot_encoding(y)\n",
    "onehot_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dropout (keep_prob) rate  0.7~0.5 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 5625, 2])\n",
    "X_img = tf.reshape(X, [-1, 75, 75, 2])   # img 28x28x1 (black/white)\n",
    "Y = tf.placeholder(tf.float32, [None, n_class])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "#    Conv     -> (?, 28, 28, 32)\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L1 = tf.nn.dropout(L1, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1],\n",
    "                    strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.nn.dropout(L2, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "Tensor(\"dropout_1/mul:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L3 ImgIn shape=(?, 7, 7, 64)\n",
    "W3 = tf.Variable(tf.random_normal([3, 3, 64, 128], stddev=0.01))\n",
    "#    Conv      ->(?, 7, 7, 128)\n",
    "#    Pool      ->(?, 4, 4, 128)\n",
    "#    Reshape   ->(?, 4 * 4 * 128) # Flatten them for FC\n",
    "L3 = tf.nn.conv2d(L2, W3, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.max_pool(L3, ksize=[1, 2, 2, 1], strides=[\n",
    "                    1, 2, 2, 1], padding='SAME')\n",
    "L3 = tf.nn.dropout(L3, keep_prob=keep_prob)\n",
    "L3_flat = tf.reshape(L3, [-1, 128 * 4 * 4])\n",
    "'''\n",
    "Tensor(\"Conv2D_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"Relu_2:0\", shape=(?, 7, 7, 128), dtype=float32)\n",
    "Tensor(\"MaxPool_2:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"dropout_2/mul:0\", shape=(?, 4, 4, 128), dtype=float32)\n",
    "Tensor(\"Reshape_1:0\", shape=(?, 2048), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L4 FC 4x4x128 inputs -> 625 outputs\n",
    "W4 = tf.get_variable(\"W4\", shape=[128 * 4 * 4, 625],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b4 = tf.Variable(tf.random_normal([625]))\n",
    "L4 = tf.nn.relu(tf.matmul(L3_flat, W4) + b4)\n",
    "L4 = tf.nn.dropout(L4, keep_prob=keep_prob)\n",
    "'''\n",
    "Tensor(\"Relu_3:0\", shape=(?, 625), dtype=float32)\n",
    "Tensor(\"dropout_3/mul:0\", shape=(?, 625), dtype=float32)\n",
    "'''\n",
    "\n",
    "# L5 Final FC 625 inputs -> 10 outputs\n",
    "W5 = tf.get_variable(\"W5\", shape=[625, 10],\n",
    "                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "b5 = tf.Variable(tf.random_normal([10]))\n",
    "logits = tf.matmul(L4, W5) + b5\n",
    "'''\n",
    "Tensor(\"add_1:0\", shape=(?, 10), dtype=float32)\n",
    "'''\n",
    "\n",
    "# define cost/loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    logits=logits, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "print('Learning started. It takes sometime.')\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys, keep_prob: 0.7}\n",
    "        c, _ = sess.run([cost, optimizer], feed_dict=feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning Finished!')\n",
    "\n",
    "# Test model and check accuracy\n",
    "\n",
    "# if you have a OOM error, please refer to lab-11-X-mnist_deep_cnn_low_memory.py\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print('Accuracy:', sess.run(accuracy, feed_dict={\n",
    "      X: mnist.test.images, Y: mnist.test.labels, keep_prob: 1}))\n",
    "\n",
    "# Get one and predict\n",
    "r = random.randint(0, mnist.test.num_examples - 1)\n",
    "print(\"Label: \", sess.run(tf.argmax(mnist.test.labels[r:r + 1], 1)))\n",
    "print(\"Prediction: \", sess.run(\n",
    "    tf.argmax(logits, 1), feed_dict={X: mnist.test.images[r:r + 1], keep_prob: 1}))\n",
    "\n",
    "# plt.imshow(mnist.test.images[r:r + 1].\n",
    "#           reshape(28, 28), cmap='Greys', interpolation='nearest')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorpack.tfutils.argscope import argscope, get_arg_scope\n",
    "from tensorpack.models import (Conv2D, GlobalAvgPooling, BatchNorm, BNReLU, FullyConnected,LinearWrap)\n",
    "\n",
    "'''\n",
    "def Conv2D(x, out_channel, kernel_shape,\n",
    "           padding='SAME', stride=1,\n",
    "           W_init=None, b_init=None,\n",
    "           nl=tf.identity, split=1, use_bias=True,\n",
    "           data_format='NHWC'):\n",
    "\n",
    "    2D convolution on 4D inputs.\n",
    "\n",
    "    Args:\n",
    "        x (tf.Tensor): a 4D tensor.\n",
    "            Must have known number of channels, but can have other unknown dimensions.\n",
    "        out_channel (int): number of output channel.\n",
    "        kernel_shape: (h, w) tuple or a int.\n",
    "        stride: (h, w) tuple or a int.\n",
    "        padding (str): 'valid' or 'same'. Case insensitive.\n",
    "        split (int): Split channels as used in Alexnet. Defaults to 1 (no split).\n",
    "        W_init: initializer for W. Defaults to `variance_scaling_initializer(2.0)`, i.e. kaiming-normal.\n",
    "        b_init: initializer for b. Defaults to zero.\n",
    "        nl: a nonlinearity function.\n",
    "        use_bias (bool): whether to use bias.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor named ``output`` with attribute `variables`.\n",
    "\n",
    "    Variable Names:\n",
    "\n",
    "    * ``W``: weights\n",
    "    * ``b``: bias\n",
    "'''\n",
    "\n",
    "def resnet_shortcut(l, n_out, stride, nl=tf.identity):\n",
    "    data_format = get_arg_scope()['Conv2D']['data_format']\n",
    "    n_in = l.get_shape().as_list()[1 if data_format == 'NCHW' else 3]\n",
    "    if n_in != n_out:   # change dimension when channel is not the same\n",
    "        return Conv2D('convshortcut', l, n_out, 1, stride=stride, nl=nl)\n",
    "    else:\n",
    "        return l\n",
    "\n",
    "\n",
    "def apply_preactivation(l, preact):\n",
    "    if preact == 'bnrelu':\n",
    "        shortcut = l    # preserve identity mapping\n",
    "        l = BNReLU('preact', l)\n",
    "    else:\n",
    "        shortcut = l\n",
    "    return l, shortcut\n",
    "\n",
    "\n",
    "def get_bn(zero_init=False):\n",
    "    \"\"\"\n",
    "    Zero init gamma is good for resnet. See https://arxiv.org/abs/1706.02677.\n",
    "    \"\"\"\n",
    "    if zero_init:\n",
    "        return lambda x, name: BatchNorm('bn', x, gamma_init=tf.zeros_initializer())\n",
    "    else:\n",
    "        return lambda x, name: BatchNorm('bn', x)\n",
    "\n",
    "\n",
    "def preresnet_basicblock(l, ch_out, stride, preact):\n",
    "    l, shortcut = apply_preactivation(l, preact)\n",
    "    l = Conv2D('conv1', l, ch_out, 3, stride=stride, nl=BNReLU)\n",
    "    l = Conv2D('conv2', l, ch_out, 3)\n",
    "    return l + resnet_shortcut(shortcut, ch_out, stride)\n",
    "\n",
    "\n",
    "def preresnet_bottleneck(l, ch_out, stride, preact):\n",
    "    # stride is applied on the second conv, following fb.resnet.torch\n",
    "    l, shortcut = apply_preactivation(l, preact)\n",
    "    l = Conv2D('conv1', l, ch_out, 1, nl=BNReLU)\n",
    "    l = Conv2D('conv2', l, ch_out, 3, stride=stride, nl=BNReLU)\n",
    "    l = Conv2D('conv3', l, ch_out * 4, 1)\n",
    "    return l + resnet_shortcut(shortcut, ch_out * 4, stride)\n",
    "\n",
    "\n",
    "def preresnet_group(l, name, block_func, features, count, stride):\n",
    "    with tf.variable_scope(name):\n",
    "        for i in range(0, count):\n",
    "            with tf.variable_scope('block{}'.format(i)):\n",
    "                # first block doesn't need activation\n",
    "                l = block_func(l, features,\n",
    "                               stride if i == 0 else 1,\n",
    "                               'no_preact' if i == 0 else 'bnrelu')\n",
    "        # end of each group need an extra activation\n",
    "        l = BNReLU('bnlast', l)\n",
    "    return l\n",
    "\n",
    "\n",
    "def resnet_basicblock(l, ch_out, stride):\n",
    "    shortcut = l\n",
    "    l = Conv2D('conv1', l, ch_out, 3, stride=stride, nl=BNReLU)\n",
    "    l = Conv2D('conv2', l, ch_out, 3, nl=get_bn(zero_init=True))\n",
    "    return l + resnet_shortcut(shortcut, ch_out, stride, nl=get_bn(zero_init=False))\n",
    "\n",
    "\n",
    "def resnet_bottleneck(l, ch_out, stride, stride_first=False):\n",
    "    \"\"\"\n",
    "    stride_first: original resnet put stride on first conv. fb.resnet.torch put stride on second conv.\n",
    "    \"\"\"\n",
    "    shortcut = l\n",
    "    l = Conv2D('conv1', l, ch_out, 1, stride=stride if stride_first else 1, nl=BNReLU)\n",
    "    l = Conv2D('conv2', l, ch_out, 3, stride=1 if stride_first else stride, nl=BNReLU)\n",
    "    l = Conv2D('conv3', l, ch_out * 4, 1, nl=get_bn(zero_init=True))\n",
    "    return l + resnet_shortcut(shortcut, ch_out * 4, stride, nl=get_bn(zero_init=False))\n",
    "\n",
    "\n",
    "def se_resnet_bottleneck(l, ch_out, stride):\n",
    "    shortcut = l\n",
    "    l = Conv2D('conv1', l, ch_out, 1, nl=BNReLU)\n",
    "    l = Conv2D('conv2', l, ch_out, 3, stride=stride, nl=BNReLU)\n",
    "    l = Conv2D('conv3', l, ch_out * 4, 1, nl=get_bn(zero_init=True))\n",
    "\n",
    "    squeeze = GlobalAvgPooling('gap', l)\n",
    "    squeeze = FullyConnected('fc1', squeeze, ch_out // 4, nl=tf.nn.relu)\n",
    "    squeeze = FullyConnected('fc2', squeeze, ch_out * 4, nl=tf.nn.sigmoid)\n",
    "    data_format = get_arg_scope()['Conv2D']['data_format']\n",
    "    ch_ax = 1 if data_format == 'NCHW' else 3\n",
    "    shape = [-1, 1, 1, 1]\n",
    "    shape[ch_ax] = ch_out * 4\n",
    "    l = l * tf.reshape(squeeze, shape)\n",
    "    return l + resnet_shortcut(shortcut, ch_out * 4, stride, nl=get_bn(zero_init=False))\n",
    "\n",
    "\n",
    "def resnet_group(l, name, block_func, features, count, stride):\n",
    "    with tf.variable_scope(name):\n",
    "        for i in range(0, count):\n",
    "            with tf.variable_scope('block{}'.format(i)):\n",
    "                l = block_func(l, features, stride if i == 0 else 1)\n",
    "                # end of each block need an activation\n",
    "                l = tf.nn.relu(l)\n",
    "    return l\n",
    "\n",
    "\n",
    "def resnet_backbone(image, num_blocks, group_func, block_func):\n",
    "    with argscope(Conv2D, nl=tf.identity, use_bias=False,\n",
    "                  W_init=tf.variance_scaling_initializer(scale=2.0, mode='fan_out')):\n",
    "        logits = (LinearWrap(image)\n",
    "                  .Conv2D('conv0', 64, 7, stride=2, nl=BNReLU)\n",
    "                  .MaxPooling('pool0', shape=3, stride=2, padding='SAME')\n",
    "                  .apply(group_func, 'group0', block_func, 64, num_blocks[0], 1)\n",
    "                  .apply(group_func, 'group1', block_func, 128, num_blocks[1], 2)\n",
    "                  .apply(group_func, 'group2', block_func, 256, num_blocks[2], 2)\n",
    "                  .apply(group_func, 'group3', block_func, 512, num_blocks[3], 2)\n",
    "                  .GlobalAvgPooling('gap')\n",
    "                  .FullyConnected('linear', 1000, nl=tf.identity)())\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imagenet-resnet.py\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: UTF-8 -*-\n",
    "# File: imagenet-resnet.py\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "\n",
    "from tensorpack import logger, QueueInput\n",
    "from tensorpack.models import *\n",
    "from tensorpack.callbacks import *\n",
    "from tensorpack.train import (\n",
    "    TrainConfig, SyncMultiGPUTrainerReplicated, launch_train_with_config)\n",
    "from tensorpack.dataflow import FakeData\n",
    "from tensorpack.tfutils import argscope, get_model_loader\n",
    "from tensorpack.utils.gpu import get_nr_gpu\n",
    "\n",
    "from imagenet_utils import (\n",
    "    fbresnet_augmentor, get_imagenet_dataflow, ImageNetModel,\n",
    "    eval_on_ILSVRC12)\n",
    "from resnet_model import (\n",
    "    preresnet_group, preresnet_basicblock, preresnet_bottleneck,\n",
    "    resnet_group, resnet_basicblock, resnet_bottleneck, se_resnet_bottleneck,\n",
    "    resnet_backbone)\n",
    "\n",
    "TOTAL_BATCH_SIZE = 256\n",
    "\n",
    "\n",
    "class Model(IcebergModel):\n",
    "    def __init__(self, depth, mode='resnet'):\n",
    "        super(Model, self).__init__(data_format)\n",
    "\n",
    "        if mode == 'se':\n",
    "            assert depth >= 50\n",
    "\n",
    "        self.mode = mode\n",
    "        basicblock = preresnet_basicblock if mode == 'preact' else resnet_basicblock\n",
    "        bottleneck = {\n",
    "            'resnet': resnet_bottleneck,\n",
    "            'preact': preresnet_bottleneck,\n",
    "            'se': se_resnet_bottleneck}[mode]\n",
    "        self.num_blocks, self.block_func = {\n",
    "            18: ([2, 2, 2, 2], basicblock),\n",
    "            34: ([3, 4, 6, 3], basicblock),\n",
    "            50: ([3, 4, 6, 3], bottleneck),\n",
    "            101: ([3, 4, 23, 3], bottleneck),\n",
    "            152: ([3, 8, 36, 3], bottleneck)\n",
    "        }[depth]\n",
    "\n",
    "    def get_logits(self, image):\n",
    "        with argscope([Conv2D, MaxPooling, GlobalAvgPooling, BatchNorm], data_format=self.data_format):\n",
    "            return resnet_backbone(\n",
    "                image, self.num_blocks,\n",
    "                preresnet_group if self.mode == 'preact' else resnet_group, self.block_func)\n",
    "\n",
    "\n",
    "def get_data(name, batch):\n",
    "    isTrain = name == 'train'\n",
    "    augmentors = fbresnet_augmentor(isTrain)\n",
    "    return get_imagenet_dataflow(\n",
    "        args.data, name, batch, augmentors)\n",
    "\n",
    "\n",
    "def get_config(model, fake=False):\n",
    "    nr_tower = max(get_nr_gpu(), 1)\n",
    "    batch = TOTAL_BATCH_SIZE // nr_tower\n",
    "\n",
    "    if fake:\n",
    "        logger.info(\"For benchmark, batch size is fixed to 64 per tower.\")\n",
    "        dataset_train = FakeData(\n",
    "            [[64, 224, 224, 3], [64]], 1000, random=False, dtype='uint8')\n",
    "        callbacks = []\n",
    "    else:\n",
    "        logger.info(\"Running on {} towers. Batch size per tower: {}\".format(nr_tower, batch))\n",
    "        dataset_train = get_data('train', batch)\n",
    "        dataset_val = get_data('val', batch)\n",
    "        callbacks = [\n",
    "            ModelSaver(),\n",
    "            ScheduledHyperParamSetter('learning_rate',\n",
    "                                      [(30, 1e-2), (60, 1e-3), (85, 1e-4), (95, 1e-5), (105, 1e-6)]),\n",
    "            HumanHyperParamSetter('learning_rate'),\n",
    "        ]\n",
    "        infs = [ClassificationError('wrong-top1', 'val-error-top1'),\n",
    "                ClassificationError('wrong-top5', 'val-error-top5')]\n",
    "        if nr_tower == 1:\n",
    "            # single-GPU inference with queue prefetch\n",
    "            callbacks.append(InferenceRunner(QueueInput(dataset_val), infs))\n",
    "        else:\n",
    "            # multi-GPU inference (with mandatory queue prefetch)\n",
    "            callbacks.append(DataParallelInferenceRunner(\n",
    "                dataset_val, infs, list(range(nr_tower))))\n",
    "\n",
    "    return TrainConfig(\n",
    "        model=model,\n",
    "        dataflow=dataset_train,\n",
    "        callbacks=callbacks,\n",
    "        steps_per_epoch=100 if args.fake else 5000,  # 5000 ~= 1.28M / TOTAL_BATCH_SIZE\n",
    "        max_epoch=110,\n",
    "        nr_tower=nr_tower\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--gpu', help='comma separated list of GPU(s) to use.')\n",
    "    parser.add_argument('--data', help='ILSVRC dataset dir')\n",
    "    parser.add_argument('--load', help='load model')\n",
    "    parser.add_argument('--fake', help='use fakedata to test or benchmark this model', action='store_true')\n",
    "    parser.add_argument('--data_format', help='specify NCHW or NHWC',\n",
    "                        type=str, default='NCHW')\n",
    "    parser.add_argument('-d', '--depth', help='resnet depth',\n",
    "                        type=int, default=18, choices=[18, 34, 50, 101, 152])\n",
    "    parser.add_argument('--eval', action='store_true')\n",
    "    parser.add_argument('--mode', choices=['resnet', 'preact', 'se'],\n",
    "                        help='variants of resnet to use', default='resnet')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if args.gpu:\n",
    "        os.environ['CUDA_VISIBLE_DEVICES'] = args.gpu\n",
    "\n",
    "    model = Model(args.depth, args.data_format, args.mode)\n",
    "    if args.eval:\n",
    "        batch = 128    # something that can run on one gpu\n",
    "        ds = get_data('val', batch)\n",
    "        eval_on_ILSVRC12(model, get_model_loader(args.load), ds)\n",
    "    else:\n",
    "        if args.fake:\n",
    "            logger.set_logger_dir(os.path.join('train_log', 'tmp'), 'd')\n",
    "        else:\n",
    "            logger.set_logger_dir(\n",
    "                os.path.join('train_log', 'imagenet-{}-d{}'.format(args.mode, args.depth)))\n",
    "\n",
    "        config = get_config(model, fake=args.fake)\n",
    "        if args.load:\n",
    "            config.session_init = get_model_loader(args.load)\n",
    "        trainer = SyncMultiGPUTrainerReplicated(max(get_nr_gpu(), 1))\n",
    "        launch_train_with_config(config, trainer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "\n",
    "__all__ = ['ResNet', 'resnet18', 'resnet34', 'resnet50', 'resnet101',\n",
    "           'resnet152']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet34': 'https://download.pytorch.org/models/resnet34-333f7ec4.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"\"\"3x3 convolution with padding\"\"\"\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
    "                     padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        self.conv3 = nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                               bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet34(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-34 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet34']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet101']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
