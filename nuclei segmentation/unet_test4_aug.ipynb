{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage.io import imsave\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "from data import *\n",
    "from keras.preprocessing.image_augmentation import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows = 256\n",
    "img_cols = 256\n",
    "\n",
    "smooth = 1.\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def get_unet():\n",
    "    inputs = Input((img_rows, img_cols, 1))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_data():\n",
    "    mydata = dataProcess(img_rows, img_cols)\n",
    "    imgs_train, imgs_mask_train = mydata.load_train_data()\n",
    "    imgs_test, imgs_id = mydata.load_test_data()\n",
    "    imgs_train = np.reshape(imgs_train, (-1, img_rows, img_cols, 1))\n",
    "    imgs_mask_train = np.reshape(imgs_mask_train, (-1, img_rows, img_cols, 1))\n",
    "    imgs_test = np.reshape(imgs_test, (-1, img_rows, img_cols, 1))\n",
    "\n",
    "    return imgs_train, imgs_mask_train, imgs_test, imgs_id\n",
    "\n",
    "def train_and_predict():\n",
    "    \n",
    "    #parameter \n",
    "    batch_size = 20\n",
    "    epochs = 50\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing train data...')\n",
    "    print('-'*30)\n",
    "    imgs_train, imgs_mask_train, imgs_test, imgs_id = load_data()\n",
    "    \n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    "\n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_mask_train /= 255.  # scale masks to [0, 1]\n",
    "    \n",
    "    x_train, y_train = imgs_train[:540], imgs_mask_train[:540]\n",
    "    x_val, y_val = imgs_train[540:], imgs_mask_train[540:]\n",
    "    \n",
    "    datagen = ImageDataGenerator(contrast_stretching=False, adaptive_equalization=False, histogram_equalization=True, \n",
    "                                 featurewise_center=False, featurewise_std_normalization=False, \n",
    "                                 rotation_range=90.,width_shift_range=0.,height_shift_range=0.,shear_range=0.,zoom_range=0.,\n",
    "                                 channel_shift_range=0.,\n",
    "                                 horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "    model = get_unet()\n",
    "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "    print('-'*30)\n",
    "    \n",
    "    datagen.fit(x_train)\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                            epochs=epochs, validation_data=(x_val, y_val), callbacks=[model_checkpoint])\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing test data...')\n",
    "    print('-'*30)\n",
    "\n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('Loading saved weights...')\n",
    "    print('-'*30)\n",
    "    model.load_weights('weights.h5')\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting masks on test data...')\n",
    "    print('-'*30)\n",
    "    \n",
    "    imgs_mask_test = model.predict(imgs_test, verbose=1, batch_size= 5)\n",
    "    np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Saving predicted masks to files...')\n",
    "    print('-' * 30)\n",
    "    pred_dir = 'test/label'\n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "    for image, image_id in zip(imgs_mask_test, imgs_id):\n",
    "        image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "        imsave(os.path.join(pred_dir, str(image_id) + '_pred.png'), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Loading and preprocessing train data...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Fitting model...\n",
      "------------------------------\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\skimage\\exposure\\exposure.py:63: UserWarning: This might be a color image. The histogram will be computed on the flattened image. You can instead apply this function to each color channel.\n",
      "  warn(\"This might be a color image. The histogram will be \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 47s 2s/step - loss: -0.2175 - dice_coef: 0.2175 - val_loss: -0.2103 - val_dice_coef: 0.2103\n",
      "Epoch 2/50\n",
      "27/27 [==============================] - 38s 1s/step - loss: -0.2188 - dice_coef: 0.2188 - val_loss: -0.2117 - val_dice_coef: 0.2117\n",
      "Epoch 3/50\n",
      "27/27 [==============================] - 38s 1s/step - loss: -0.2188 - dice_coef: 0.2188 - val_loss: -0.2132 - val_dice_coef: 0.2132\n",
      "Epoch 4/50\n",
      "27/27 [==============================] - 38s 1s/step - loss: -0.2201 - dice_coef: 0.2201 - val_loss: -0.2147 - val_dice_coef: 0.2147\n",
      "Epoch 5/50\n",
      "27/27 [==============================] - 38s 1s/step - loss: -0.2209 - dice_coef: 0.2209 - val_loss: -0.2198 - val_dice_coef: 0.2198\n",
      "Epoch 6/50\n",
      "27/27 [==============================] - 38s 1s/step - loss: -0.2343 - dice_coef: 0.2343 - val_loss: -0.2360 - val_dice_coef: 0.2360\n",
      "Epoch 7/50\n",
      "27/27 [==============================] - 36s 1s/step - loss: -0.2454 - dice_coef: 0.2454 - val_loss: -0.2355 - val_dice_coef: 0.2355\n",
      "Epoch 8/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2459 - dice_coef: 0.2459 - val_loss: -0.2355 - val_dice_coef: 0.2355\n",
      "Epoch 9/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2460 - dice_coef: 0.2460 - val_loss: -0.2355 - val_dice_coef: 0.2355\n",
      "Epoch 10/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2459 - dice_coef: 0.2459 - val_loss: -0.2355 - val_dice_coef: 0.2355\n",
      "Epoch 11/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2449 - dice_coef: 0.2449 - val_loss: -0.2355 - val_dice_coef: 0.2355\n",
      "Epoch 12/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2458 - dice_coef: 0.2458 - val_loss: -0.2355 - val_dice_coef: 0.2355\n",
      "Epoch 13/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2457 - dice_coef: 0.2457 - val_loss: -0.2355 - val_dice_coef: 0.2355\n",
      "Epoch 14/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2459 - dice_coef: 0.2459 - val_loss: -0.2355 - val_dice_coef: 0.2355\n",
      "Epoch 15/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2455 - dice_coef: 0.2455 - val_loss: -0.2355 - val_dice_coef: 0.2355\n",
      "Epoch 16/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2459 - dice_coef: 0.2459 - val_loss: -0.2355 - val_dice_coef: 0.2355\n",
      "Epoch 17/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2458 - dice_coef: 0.2458 - val_loss: -0.2355 - val_dice_coef: 0.2355\n",
      "Epoch 18/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2455 - dice_coef: 0.2455 - val_loss: -0.2355 - val_dice_coef: 0.2355\n",
      "Epoch 19/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2453 - dice_coef: 0.2453 - val_loss: -0.2355 - val_dice_coef: 0.2355\n",
      "Epoch 20/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2459 - dice_coef: 0.2459 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 21/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2458 - dice_coef: 0.2458 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 22/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2453 - dice_coef: 0.2453 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 23/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2450 - dice_coef: 0.2450 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 24/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2459 - dice_coef: 0.2459 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 25/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2458 - dice_coef: 0.2458 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 26/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2457 - dice_coef: 0.2457 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 27/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2458 - dice_coef: 0.2458 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 28/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2453 - dice_coef: 0.2453 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 29/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2459 - dice_coef: 0.2459 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 30/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2458 - dice_coef: 0.2458 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 31/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2457 - dice_coef: 0.2457 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 32/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2461 - dice_coef: 0.2461 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 33/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2460 - dice_coef: 0.2460 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 34/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2458 - dice_coef: 0.2458 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 35/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2458 - dice_coef: 0.2458 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 36/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2455 - dice_coef: 0.2455 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 37/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2459 - dice_coef: 0.2459 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 38/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2460 - dice_coef: 0.2460 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 39/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2453 - dice_coef: 0.2453 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 40/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2453 - dice_coef: 0.2453 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 41/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2454 - dice_coef: 0.2454 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 42/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2457 - dice_coef: 0.2457 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 43/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2459 - dice_coef: 0.2459 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 44/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2457 - dice_coef: 0.2457 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 45/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2459 - dice_coef: 0.2459 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 46/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2455 - dice_coef: 0.2455 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 47/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2456 - dice_coef: 0.2456 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 48/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2460 - dice_coef: 0.2460 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 49/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2460 - dice_coef: 0.2460 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "Epoch 50/50\n",
      "27/27 [==============================] - 34s 1s/step - loss: -0.2456 - dice_coef: 0.2456 - val_loss: -0.2354 - val_dice_coef: 0.2354\n",
      "------------------------------\n",
      "Loading and preprocessing test data...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Loading saved weights...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Predicting masks on test data...\n",
      "------------------------------\n",
      "65/65 [==============================] - 2s 30ms/step\n",
      "------------------------------\n",
      "Saving predicted masks to files...\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_and_predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
