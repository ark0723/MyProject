{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "from data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\keras\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows = 256\n",
    "img_cols = 256\n",
    "\n",
    "smooth = 1.\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def get_unet():\n",
    "    inputs = Input((img_rows, img_cols, 1))\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_data():\n",
    "\n",
    "    mydata = dataProcess(img_rows, img_cols)\n",
    "    imgs_train, imgs_mask_train = mydata.load_train_data()\n",
    "    imgs_test, imgs_id = mydata.load_test_data()\n",
    "    imgs_train = np.reshape(imgs_train, (-1, img_rows, img_cols, 1))\n",
    "    imgs_mask_train = np.reshape(imgs_mask_train, (-1, img_rows, img_cols, 1))\n",
    "    imgs_test = np.reshape(imgs_test, (-1, img_rows, img_cols, 1))\n",
    "\n",
    "    return imgs_train, imgs_mask_train, imgs_test, imgs_id\n",
    "\n",
    "def train_and_predict():\n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing train data...')\n",
    "    print('-'*30)\n",
    "    imgs_train, imgs_mask_train, imgs_test, imgs_id = load_data()\n",
    "\n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    "\n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_mask_train /= 255.  # scale masks to [0, 1]\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "    model = get_unet()\n",
    "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "    print('-'*30)\n",
    "    model.fit(imgs_train, imgs_mask_train, batch_size=5, nb_epoch=50, verbose=1, shuffle=True,\n",
    "              validation_split=0.2,\n",
    "              callbacks=[model_checkpoint])\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing test data...')\n",
    "    print('-'*30)\n",
    "\n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading saved weights...')\n",
    "    print('-'*30)\n",
    "    model.load_weights('weights.h5')\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting masks on test data...')\n",
    "    print('-'*30)\n",
    "    imgs_mask_test = model.predict(imgs_test, verbose=1, batch_size= 5)\n",
    "    np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Saving predicted masks to files...')\n",
    "    print('-' * 30)\n",
    "    pred_dir = 'test/label'\n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "    for image, image_id in zip(imgs_mask_test, imgs_id):\n",
    "        image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "        imsave(os.path.join(pred_dir, str(image_id) + '_pred.png'), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Loading and preprocessing train data...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Fitting model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:101: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 536 samples, validate on 134 samples\n",
      "Epoch 1/50\n",
      "536/536 [==============================] - 107s 200ms/step - loss: -0.2309 - dice_coef: 0.2309 - val_loss: -0.2513 - val_dice_coef: 0.2513\n",
      "Epoch 2/50\n",
      "536/536 [==============================] - 98s 182ms/step - loss: -0.2957 - dice_coef: 0.2957 - val_loss: -0.3472 - val_dice_coef: 0.3472\n",
      "Epoch 3/50\n",
      "536/536 [==============================] - 96s 179ms/step - loss: -0.5184 - dice_coef: 0.5184 - val_loss: -0.6116 - val_dice_coef: 0.6116\n",
      "Epoch 4/50\n",
      "536/536 [==============================] - 96s 179ms/step - loss: -0.6471 - dice_coef: 0.6471 - val_loss: -0.7119 - val_dice_coef: 0.7119\n",
      "Epoch 5/50\n",
      "536/536 [==============================] - 95s 178ms/step - loss: -0.7022 - dice_coef: 0.7022 - val_loss: -0.7582 - val_dice_coef: 0.7582\n",
      "Epoch 6/50\n",
      "536/536 [==============================] - 96s 179ms/step - loss: -0.7127 - dice_coef: 0.7127 - val_loss: -0.7648 - val_dice_coef: 0.7648\n",
      "Epoch 7/50\n",
      "536/536 [==============================] - 95s 178ms/step - loss: -0.7579 - dice_coef: 0.7579 - val_loss: -0.7745 - val_dice_coef: 0.7745\n",
      "Epoch 8/50\n",
      "536/536 [==============================] - 96s 178ms/step - loss: -0.7628 - dice_coef: 0.7628 - val_loss: -0.8112 - val_dice_coef: 0.8112\n",
      "Epoch 9/50\n",
      "536/536 [==============================] - 96s 179ms/step - loss: -0.7814 - dice_coef: 0.7814 - val_loss: -0.8123 - val_dice_coef: 0.8123\n",
      "Epoch 10/50\n",
      "536/536 [==============================] - 95s 178ms/step - loss: -0.8027 - dice_coef: 0.8027 - val_loss: -0.8364 - val_dice_coef: 0.8364\n",
      "Epoch 11/50\n",
      "536/536 [==============================] - 95s 178ms/step - loss: -0.8171 - dice_coef: 0.8171 - val_loss: -0.8412 - val_dice_coef: 0.8412\n",
      "Epoch 12/50\n",
      "536/536 [==============================] - 95s 178ms/step - loss: -0.8281 - dice_coef: 0.8281 - val_loss: -0.8535 - val_dice_coef: 0.8535\n",
      "Epoch 13/50\n",
      "536/536 [==============================] - 95s 177ms/step - loss: -0.8344 - dice_coef: 0.8344 - val_loss: -0.8567 - val_dice_coef: 0.8567\n",
      "Epoch 14/50\n",
      "536/536 [==============================] - 95s 177ms/step - loss: -0.8375 - dice_coef: 0.8375 - val_loss: -0.8521 - val_dice_coef: 0.8521\n",
      "Epoch 15/50\n",
      "536/536 [==============================] - 96s 179ms/step - loss: -0.8442 - dice_coef: 0.8442 - val_loss: -0.8652 - val_dice_coef: 0.8652\n",
      "Epoch 16/50\n",
      "536/536 [==============================] - 96s 178ms/step - loss: -0.8501 - dice_coef: 0.8501 - val_loss: -0.8703 - val_dice_coef: 0.8703\n",
      "Epoch 17/50\n",
      "536/536 [==============================] - 94s 176ms/step - loss: -0.8546 - dice_coef: 0.8546 - val_loss: -0.8702 - val_dice_coef: 0.8702\n",
      "Epoch 18/50\n",
      "536/536 [==============================] - 94s 176ms/step - loss: -0.8577 - dice_coef: 0.8577 - val_loss: -0.8637 - val_dice_coef: 0.8637\n",
      "Epoch 19/50\n",
      "536/536 [==============================] - 95s 177ms/step - loss: -0.8530 - dice_coef: 0.8530 - val_loss: -0.8779 - val_dice_coef: 0.8779\n",
      "Epoch 20/50\n",
      "536/536 [==============================] - 94s 176ms/step - loss: -0.8628 - dice_coef: 0.8628 - val_loss: -0.8767 - val_dice_coef: 0.8767\n",
      "Epoch 21/50\n",
      "536/536 [==============================] - 94s 176ms/step - loss: -0.8588 - dice_coef: 0.8588 - val_loss: -0.8716 - val_dice_coef: 0.8716\n",
      "Epoch 22/50\n",
      "536/536 [==============================] - 95s 177ms/step - loss: -0.8645 - dice_coef: 0.8645 - val_loss: -0.8665 - val_dice_coef: 0.8665\n",
      "Epoch 23/50\n",
      "536/536 [==============================] - 95s 177ms/step - loss: -0.8680 - dice_coef: 0.8680 - val_loss: -0.8727 - val_dice_coef: 0.8727\n",
      "Epoch 24/50\n",
      "536/536 [==============================] - 96s 179ms/step - loss: -0.8587 - dice_coef: 0.8587 - val_loss: -0.8837 - val_dice_coef: 0.8837\n",
      "Epoch 25/50\n",
      "536/536 [==============================] - 95s 178ms/step - loss: -0.8721 - dice_coef: 0.8721 - val_loss: -0.8851 - val_dice_coef: 0.8851\n",
      "Epoch 26/50\n",
      "536/536 [==============================] - 94s 176ms/step - loss: -0.8741 - dice_coef: 0.8741 - val_loss: -0.8846 - val_dice_coef: 0.8846\n",
      "Epoch 27/50\n",
      "536/536 [==============================] - 95s 176ms/step - loss: -0.8738 - dice_coef: 0.8738 - val_loss: -0.8763 - val_dice_coef: 0.8763\n",
      "Epoch 28/50\n",
      "536/536 [==============================] - 95s 176ms/step - loss: -0.8732 - dice_coef: 0.8732 - val_loss: -0.8793 - val_dice_coef: 0.8793\n",
      "Epoch 29/50\n",
      "536/536 [==============================] - 95s 177ms/step - loss: -0.8816 - dice_coef: 0.8816 - val_loss: -0.8751 - val_dice_coef: 0.8751\n",
      "Epoch 30/50\n",
      "536/536 [==============================] - 96s 178ms/step - loss: -0.8802 - dice_coef: 0.8802 - val_loss: -0.8868 - val_dice_coef: 0.8868\n",
      "Epoch 31/50\n",
      "536/536 [==============================] - 95s 178ms/step - loss: -0.8791 - dice_coef: 0.8791 - val_loss: -0.8881 - val_dice_coef: 0.8881\n",
      "Epoch 32/50\n",
      "536/536 [==============================] - 95s 177ms/step - loss: -0.8841 - dice_coef: 0.8841 - val_loss: -0.8937 - val_dice_coef: 0.8937\n",
      "Epoch 33/50\n",
      "536/536 [==============================] - 94s 176ms/step - loss: -0.8785 - dice_coef: 0.8785 - val_loss: -0.8898 - val_dice_coef: 0.8898\n",
      "Epoch 34/50\n",
      "536/536 [==============================] - 95s 176ms/step - loss: -0.8827 - dice_coef: 0.8827 - val_loss: -0.8856 - val_dice_coef: 0.8856\n",
      "Epoch 35/50\n",
      "536/536 [==============================] - 95s 178ms/step - loss: -0.8865 - dice_coef: 0.8865 - val_loss: -0.8953 - val_dice_coef: 0.8953\n",
      "Epoch 36/50\n",
      "536/536 [==============================] - 94s 175ms/step - loss: -0.8845 - dice_coef: 0.8845 - val_loss: -0.8910 - val_dice_coef: 0.8910\n",
      "Epoch 37/50\n",
      "536/536 [==============================] - 94s 176ms/step - loss: -0.8854 - dice_coef: 0.8854 - val_loss: -0.8880 - val_dice_coef: 0.8880\n",
      "Epoch 38/50\n",
      "536/536 [==============================] - 94s 175ms/step - loss: -0.8881 - dice_coef: 0.8881 - val_loss: -0.8945 - val_dice_coef: 0.8945\n",
      "Epoch 39/50\n",
      "536/536 [==============================] - 94s 176ms/step - loss: -0.8848 - dice_coef: 0.8848 - val_loss: -0.8891 - val_dice_coef: 0.8891\n",
      "Epoch 40/50\n",
      "536/536 [==============================] - 95s 177ms/step - loss: -0.8896 - dice_coef: 0.8896 - val_loss: -0.8968 - val_dice_coef: 0.8968\n",
      "Epoch 41/50\n",
      "536/536 [==============================] - 94s 176ms/step - loss: -0.8926 - dice_coef: 0.8926 - val_loss: -0.8953 - val_dice_coef: 0.8953\n",
      "Epoch 42/50\n",
      "536/536 [==============================] - 94s 176ms/step - loss: -0.8932 - dice_coef: 0.8932 - val_loss: -0.8966 - val_dice_coef: 0.8966\n",
      "Epoch 43/50\n",
      "536/536 [==============================] - 95s 178ms/step - loss: -0.8960 - dice_coef: 0.8960 - val_loss: -0.8970 - val_dice_coef: 0.8970\n",
      "Epoch 44/50\n",
      "536/536 [==============================] - 95s 178ms/step - loss: -0.8877 - dice_coef: 0.8877 - val_loss: -0.9013 - val_dice_coef: 0.9013\n",
      "Epoch 45/50\n",
      "536/536 [==============================] - 95s 177ms/step - loss: -0.8989 - dice_coef: 0.8989 - val_loss: -0.9017 - val_dice_coef: 0.9017\n",
      "Epoch 46/50\n",
      "536/536 [==============================] - 95s 177ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.8970 - val_dice_coef: 0.8970\n",
      "Epoch 47/50\n",
      "536/536 [==============================] - 96s 179ms/step - loss: -0.8986 - dice_coef: 0.8986 - val_loss: -0.9025 - val_dice_coef: 0.9025\n",
      "Epoch 48/50\n",
      "536/536 [==============================] - 95s 178ms/step - loss: -0.9015 - dice_coef: 0.9015 - val_loss: -0.9032 - val_dice_coef: 0.9032\n",
      "Epoch 49/50\n",
      "536/536 [==============================] - 95s 178ms/step - loss: -0.8985 - dice_coef: 0.8985 - val_loss: -0.9038 - val_dice_coef: 0.9038\n",
      "Epoch 50/50\n",
      "536/536 [==============================] - 94s 176ms/step - loss: -0.8984 - dice_coef: 0.8984 - val_loss: -0.9033 - val_dice_coef: 0.9033\n",
      "------------------------------\n",
      "Loading and preprocessing test data...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Loading saved weights...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Predicting masks on test data...\n",
      "------------------------------\n",
      "65/65 [==============================] - 3s 43ms/step\n",
      "------------------------------\n",
      "Saving predicted masks to files...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\skimage\\io\\_io.py:132: UserWarning: test/label\\30_pred.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\skimage\\io\\_io.py:132: UserWarning: test/label\\35_pred.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n",
      "C:\\Users\\User\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\skimage\\io\\_io.py:132: UserWarning: test/label\\56_pred.png is a low contrast image\n",
      "  warn('%s is a low contrast image' % fname)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_and_predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
