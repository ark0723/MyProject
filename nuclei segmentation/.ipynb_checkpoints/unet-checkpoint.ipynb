{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## unet modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os \n",
    "#os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import Input, merge, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Cropping2D\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "unet with crop(because padding = valid) \n",
    "\n",
    "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(inputs)\n",
    "print \"conv1 shape:\",conv1.shape\n",
    "conv1 = Conv2D(64, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv1)\n",
    "print \"conv1 shape:\",conv1.shape\n",
    "crop1 = Cropping2D(cropping=((90,90),(90,90)))(conv1)\n",
    "print \"crop1 shape:\",crop1.shape\n",
    "pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "print \"pool1 shape:\",pool1.shape\n",
    "\n",
    "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(pool1)\n",
    "print \"conv2 shape:\",conv2.shape\n",
    "conv2 = Conv2D(128, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv2)\n",
    "print \"conv2 shape:\",conv2.shape\n",
    "crop2 = Cropping2D(cropping=((41,41),(41,41)))(conv2)\n",
    "print \"crop2 shape:\",crop2.shape\n",
    "pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "print \"pool2 shape:\",pool2.shape\n",
    "\n",
    "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(pool2)\n",
    "print \"conv3 shape:\",conv3.shape\n",
    "conv3 = Conv2D(256, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv3)\n",
    "print \"conv3 shape:\",conv3.shape\n",
    "crop3 = Cropping2D(cropping=((16,17),(16,17)))(conv3)\n",
    "print \"crop3 shape:\",crop3.shape\n",
    "pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "print \"pool3 shape:\",pool3.shape\n",
    "\n",
    "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(pool3)\n",
    "conv4 = Conv2D(512, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv4)\n",
    "drop4 = Dropout(0.5)(conv4)\n",
    "crop4 = Cropping2D(cropping=((4,4),(4,4)))(drop4)\n",
    "pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(pool4)\n",
    "conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv5)\n",
    "drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "merge6 = merge([crop4,up6], mode = 'concat', concat_axis = 3)\n",
    "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(merge6)\n",
    "conv6 = Conv2D(512, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "merge7 = merge([crop3,up7], mode = 'concat', concat_axis = 3)\n",
    "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(merge7)\n",
    "conv7 = Conv2D(256, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "merge8 = merge([crop2,up8], mode = 'concat', concat_axis = 3)\n",
    "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(merge8)\n",
    "conv8 = Conv2D(128, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv8)\n",
    "up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "merge9 = merge([crop1,up9], mode = 'concat', concat_axis = 3)\n",
    "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(merge9)\n",
    "conv9 = Conv2D(64, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv9)\n",
    "conv9 = Conv2D(2, 3, activation = 'relu', padding = 'valid', kernel_initializer = 'he_normal')(conv9)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'data/validation',\n",
    "        target_size=(150, 150),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# we create two instances with the same arguments\n",
    "data_gen_args = dict(featurewise_center=True,\n",
    "                     featurewise_std_normalization=True,\n",
    "                     rotation_range=90.,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     zoom_range=0.2)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "image_datagen.fit(images, augment=True, seed=seed)\n",
    "mask_datagen.fit(masks, augment=True, seed=seed)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    'data/images',\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\n",
    "    'data/masks',\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=2000,\n",
    "    epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class myUnet(object):\n",
    "\n",
    "    def __init__(self, img_rows = 256, img_cols = 256):\n",
    "\n",
    "        self.img_rows = img_rows\n",
    "        self.img_cols = img_cols\n",
    "\n",
    "    def load_data(self):\n",
    "        '''\n",
    "        # we create two instances with the same arguments\n",
    "        data_gen_args = dict(featurewise_center=True,featurewise_std_normalization=True, width_shift_range=0.1,\n",
    "                             height_shift_range=0.1,zoom_range=0.2,horizontal_flip=True)\n",
    "\n",
    "        image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "        mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "        # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "        seed = 1\n",
    "        image_datagen.fit(images, augment=True, seed=seed)\n",
    "        mask_datagen.fit(masks, augment=True, seed=seed)\n",
    "\n",
    "        image_generator = image_datagen.flow_from_directory('train/image',color_mode=\"rgb\", class_mode=None, seed=seed)\n",
    "        #color_mode: one of \"grayscale\", \"rbg\". Default: \"rgb\"\n",
    "        mask_generator = mask_datagen.flow_from_directory('train/label', class_mode=None, seed=seed)\n",
    "\n",
    "        # combine generators into one which yields image and masks\n",
    "        train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "        model.fit_generator(train_generator, steps_per_epoch=2000, epochs=50)\n",
    "        '''\n",
    "        mydata = dataProcess(self.img_rows, self.img_cols)\n",
    "        imgs_train, imgs_mask_train = mydata.load_train_data()\n",
    "        imgs_test = mydata.load_test_data()\n",
    "        return imgs_train, imgs_mask_train, imgs_test\n",
    "        \n",
    "    def get_unet(self):\n",
    "\n",
    "        inputs = Input((self.img_rows, self.img_cols,1))\n",
    "\n",
    "        conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "        print \"conv1 shape:\",conv1.shape\n",
    "        conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "        print \"conv1 shape:\",conv1.shape\n",
    "        pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "        print \"pool1 shape:\",pool1.shape\n",
    "\n",
    "        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "        print \"conv2 shape:\",conv2.shape\n",
    "        conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "        print \"conv2 shape:\",conv2.shape\n",
    "        pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "        print \"pool2 shape:\",pool2.shape\n",
    "\n",
    "        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "        print \"conv3 shape:\",conv3.shape\n",
    "        conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "        print \"conv3 shape:\",conv3.shape\n",
    "        pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "        print \"pool3 shape:\",pool3.shape\n",
    "\n",
    "        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "        conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "        drop4 = Dropout(0.5)(conv4)\n",
    "        pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "        conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "        conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "        drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "        up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "        merge6 = merge([drop4,up6], mode = 'concat', concat_axis = 3)\n",
    "        conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "        conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "        up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "        merge7 = merge([conv3,up7], mode = 'concat', concat_axis = 3)\n",
    "        conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "        conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "        up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "        merge8 = merge([conv2,up8], mode = 'concat', concat_axis = 3)\n",
    "        conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "        conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "        up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "        merge9 = merge([conv1,up9], mode = 'concat', concat_axis = 3)\n",
    "        conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "        conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "        conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "        model = Model(input = inputs, output = conv10)\n",
    "        model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "        return model\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        print(\"loading data\")\n",
    "        imgs_train, imgs_mask_train, imgs_test = self.load_data()\n",
    "        print(\"loading data done\")\n",
    "        model = self.get_unet()\n",
    "        print(\"got unet\")\n",
    "\n",
    "        model_checkpoint = ModelCheckpoint('unet.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "        print('Fitting model...')\n",
    "        model.fit(imgs_train, imgs_mask_train, batch_size=4, nb_epoch=10, verbose=1,validation_split=0.2, shuffle=True, callbacks=[model_checkpoint])\n",
    "\n",
    "        print('predict test data')\n",
    "        imgs_mask_test = model.predict(imgs_test, batch_size=1, verbose=1)\n",
    "        np.save('../results/imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "    def save_img(self):\n",
    "\n",
    "        print(\"array to image\")\n",
    "        imgs = np.load('imgs_mask_test.npy')\n",
    "        for i in range(imgs.shape[0]):\n",
    "            img = imgs[i]\n",
    "            img = array_to_img(img)\n",
    "            img.save(\"../results/%d.jpg\"%(i))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    myunet = myUnet()\n",
    "    myunet.train()\n",
    "    myunet.save_img()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from skimage.transform import resize\n",
    "from skimage.io import imsave\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "from data import load_train_data, load_test_data\n",
    "\n",
    "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n",
    "\n",
    "img_rows = 96\n",
    "img_cols = 96\n",
    "\n",
    "smooth = 1.\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def get_unet():\n",
    "    inputs = Input((img_rows, img_cols, 1))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def preprocess(imgs):\n",
    "    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols), dtype=np.uint8)\n",
    "    for i in range(imgs.shape[0]):\n",
    "        imgs_p[i] = resize(imgs[i], (img_cols, img_rows), preserve_range=True)\n",
    "\n",
    "    imgs_p = imgs_p[..., np.newaxis]\n",
    "    return imgs_p\n",
    "\n",
    "\n",
    "def train_and_predict():\n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing train data...')\n",
    "    print('-'*30)\n",
    "    imgs_train, imgs_mask_train = load_train_data()\n",
    "\n",
    "    imgs_train = preprocess(imgs_train)\n",
    "    imgs_mask_train = preprocess(imgs_mask_train)\n",
    "\n",
    "    imgs_train = imgs_train.astype('float32')\n",
    "    mean = np.mean(imgs_train)  # mean for data centering\n",
    "    std = np.std(imgs_train)  # std for data normalization\n",
    "\n",
    "    imgs_train -= mean\n",
    "    imgs_train /= std\n",
    "\n",
    "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
    "    imgs_mask_train /= 255.  # scale masks to [0, 1]\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "    model = get_unet()\n",
    "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "    print('-'*30)\n",
    "    model.fit(imgs_train, imgs_mask_train, batch_size=32, nb_epoch=20, verbose=1, shuffle=True,\n",
    "              validation_split=0.2,\n",
    "              callbacks=[model_checkpoint])\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing test data...')\n",
    "    print('-'*30)\n",
    "    imgs_test, imgs_id_test = load_test_data()\n",
    "    imgs_test = preprocess(imgs_test)\n",
    "\n",
    "    imgs_test = imgs_test.astype('float32')\n",
    "    imgs_test -= mean\n",
    "    imgs_test /= std\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading saved weights...')\n",
    "    print('-'*30)\n",
    "    model.load_weights('weights.h5')\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting masks on test data...')\n",
    "    print('-'*30)\n",
    "    imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
    "    np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Saving predicted masks to files...')\n",
    "    print('-' * 30)\n",
    "    pred_dir = 'preds'\n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "    for image, image_id in zip(imgs_mask_test, imgs_id_test):\n",
    "        image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "        imsave(os.path.join(pred_dir, str(image_id) + '_pred.png'), image)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train_and_predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
