{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage.io import imsave\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "\n",
    "from data import *\n",
    "from keras.preprocessing.image_augmentation import ImageDataGenerator, array_to_img, img_to_array, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows = 256\n",
    "img_cols = 256\n",
    "\n",
    "smooth = 1.\n",
    "\n",
    "\n",
    "def dice_coef(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "\n",
    "def dice_coef_loss(y_true, y_pred):\n",
    "    return -dice_coef(y_true, y_pred)\n",
    "\n",
    "\n",
    "def get_unet():\n",
    "    inputs = Input((img_rows, img_cols, 1))\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
    "    conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
    "    conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
    "    conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
    "    conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
    "    conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
    "    conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
    "    conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
    "    conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
    "\n",
    "    conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
    "\n",
    "    model = Model(inputs=[inputs], outputs=[conv10])\n",
    "\n",
    "    model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
    "\n",
    "    return model\n",
    "\n",
    "def load_data():\n",
    "    mydata = dataProcess(img_rows, img_cols)\n",
    "    imgs_train, imgs_mask_train = mydata.load_train_data()\n",
    "    imgs_test, imgs_id = mydata.load_test_data()\n",
    "    imgs_train = np.reshape(imgs_train, (-1, img_rows, img_cols, 1))\n",
    "    imgs_mask_train = np.reshape(imgs_mask_train, (-1, img_rows, img_cols, 1))\n",
    "    imgs_test = np.reshape(imgs_test, (-1, img_rows, img_cols, 1))\n",
    "\n",
    "    return imgs_train, imgs_mask_train, imgs_test, imgs_id\n",
    "\n",
    "def train_and_predict():\n",
    "    \n",
    "    #parameter \n",
    "    batch_size = 20\n",
    "    epochs = 50\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing train data...')\n",
    "    print('-'*30)\n",
    "    \n",
    "    imgs_train, imgs_mask_train, imgs_test, imgs_id = load_data()\n",
    "    #x_train, y_train = imgs_train[:540], imgs_mask_train[:540]\n",
    "    #x_val, y_val = imgs_train[540:], imgs_mask_train[540:]\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing train data...')\n",
    "    print('-'*30)\n",
    "   \n",
    "    # we create two instances with the same arguments\n",
    "    data_gen_args = dict(featurewise_center=True, featurewise_std_normalization=True, rescale=1./255, \n",
    "                        zca_whitening =True,\n",
    "                        rotation_range=90.,width_shift_range=0.,height_shift_range=0.,zoom_range=0.,\n",
    "                        horizontal_flip=True, vertical_flip=True)\n",
    "    \n",
    "    image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "    \n",
    "    print('-'*30)\n",
    "    print('Creating and compiling model...')\n",
    "    print('-'*30)\n",
    "    model = get_unet()\n",
    "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Fitting model...')\n",
    "    print('-'*30)\n",
    "    \n",
    "    # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "    seed = 1\n",
    "    image_datagen.fit(imgs_train, augment=True, seed=seed)\n",
    "    mask_datagen.fit(imgs_mask_train, augment=True, seed=seed)\n",
    "\n",
    "    ## set the parameters for the data to come from (images)\n",
    "    image_generator = image_datagen.flow(imgs_train, batch_size=10, shuffle=True,seed=seed)\n",
    "    ## set the parameters for the data to come from (masks)\n",
    "    mask_generator = mask_datagen.flow(imgs_mask_train, batch_size=10, shuffle=True, seed=seed)\n",
    "    \n",
    "    # combine generators into one which yields image and masks\n",
    "    train_generator = zip(image_generator, mask_generator)\n",
    "    \n",
    "    model.fit_generator(train_generator, steps_per_epoch= 670//batch_size, epochs = epochs, callbacks=[model_checkpoint])\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading and preprocessing test data...')\n",
    "    print('-'*30)\n",
    "\n",
    "    #imgs_test = imgs_test.astype('float32')\n",
    "    #imgs_test -= mean\n",
    "    #imgs_test /= std\n",
    "    test_image_datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True, rescale=1./255)\n",
    "    test_image_generator = image_datagen.flow(imgs_test, batch_size=10, shuffle= False)\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Loading saved weights...')\n",
    "    print('-'*30)\n",
    "    model.load_weights('weights.h5')\n",
    "\n",
    "    print('-'*30)\n",
    "    print('Predicting masks on test data...')\n",
    "    print('-'*30)\n",
    "    \n",
    "    imgs_mask_test = model.predict_generator(test_image_generator, steps=None, verbose=0)\n",
    "    np.save('imgs_mask_test.npy', imgs_mask_test)\n",
    "\n",
    "    print('-' * 30)\n",
    "    print('Saving predicted masks to files...')\n",
    "    print('-' * 30)\n",
    "    pred_dir = 'test/label'\n",
    "    if not os.path.exists(pred_dir):\n",
    "        os.mkdir(pred_dir)\n",
    "    for image, image_id in zip(imgs_mask_test, imgs_id):\n",
    "        image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
    "        imsave(os.path.join(pred_dir, str(image_id) + '_pred.png'), image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Loading and preprocessing train data...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Loading and preprocessing train data...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Creating and compiling model...\n",
      "------------------------------\n",
      "------------------------------\n",
      "Fitting model...\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    train_and_predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 참조코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "img_dir = \"train/gray_resized_image/{}.png\"\n",
    "label_dir = \"train/label/{}.png\"\n",
    "\n",
    "x_train = np.zeros((5,256,256))\n",
    "y_train = np.zeros((5,256,256))\n",
    "for i in range(5):\n",
    "    im = Image.open(img_dir.format(i+1))\n",
    "    label = Image.open(label_dir.format(i+1))\n",
    "    im_arr = np.array(im)\n",
    "    lab_arr = np.array(label)\n",
    "    x_train[i]=im_arr\n",
    "    y_train[i]=lab_arr\n",
    "            \n",
    "\n",
    "datagen = ImageDataGenerator(contrast_stretching=True, adaptive_equalization=False, histogram_equalization=False, \n",
    "                             featurewise_center=False, samplewise_center=False,\n",
    "                             featurewise_std_normalization=False, samplewise_std_normalization=False,\n",
    "                             rotation_range=0.,width_shift_range=0.,height_shift_range=0.,shear_range=0.,zoom_range=0.,\n",
    "                             channel_shift_range=0.,\n",
    "                             horizontal_flip=True, vertical_flip=True)\n",
    "\n",
    "datagen.fit(x_train)\n",
    "history = model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        steps_per_epoch=x_train.shape[0] // batch_size,\n",
    "                        epochs=20,\n",
    "                        validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we create two instances with the same arguments\n",
    "data_gen_args = dict(featurewise_center=True,\n",
    "                     featurewise_std_normalization=True,\n",
    "                     rotation_range=90.,\n",
    "                     width_shift_range=0.1,\n",
    "                     height_shift_range=0.1,\n",
    "                     zoom_range=0.2)\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "\n",
    "# Provide the same seed and keyword arguments to the fit and flow methods\n",
    "seed = 1\n",
    "image_datagen.fit(images, augment=True, seed=seed)\n",
    "mask_datagen.fit(masks, augment=True, seed=seed)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    'data/images',\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\n",
    "    'data/masks',\n",
    "    class_mode=None,\n",
    "    seed=seed)\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "train_generator = zip(image_generator, mask_generator)\n",
    "\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=2000\n",
    "    epochs=50)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
    "\n",
    "input_path = 'dog.jpg'\n",
    "output_path = 'dog_random{}.jpg'\n",
    "count = 10\n",
    "\n",
    "gen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# load image to array\n",
    "image = img_to_array(load_img(input_path))\n",
    "\n",
    "# reshape to array rank 4\n",
    "image = image.reshape((1,) + image.shape)\n",
    "\n",
    "# let's create infinite flow of images\n",
    "images_flow = gen.flow(image, batch_size=1)\n",
    "for i, new_images in enumerate(images_flow):\n",
    "    # we access only first image because of batch_size=1\n",
    "    new_image = array_to_img(new_images[0], scale=True)\n",
    "    new_image.save(output_path.format(i + 1))\n",
    "    if i >= count:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
